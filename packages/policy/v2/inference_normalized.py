#!/usr/bin/env python3
"""
v2 ì •ê·œí™”ëœ Motion RCFM ì¶”ë¡  ì—”ì§„
fm-main í˜¸í™˜ êµ¬ì¡° + ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì ìš©
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path
import time
import glob
import open3d as o3d
import json
from datetime import datetime

from models import get_model
from utils.Lie import *
from omegaconf import OmegaConf
from utils.normalization import TwistNormalizer

class NormalizedMotionRCFMInference:
    """ì •ê·œí™”ëœ Motion RCFM ì¶”ë¡  ì—”ì§„ (v2 fm-main í˜¸í™˜)"""
    
    def __init__(self, model_path: str, config_path: str, 
                 normalize_twist: bool = True,
                 normalization_stats_path: str = "configs/normalization_stats.json"):
        """ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ì„¤ì • ë¡œë“œ
        self.config = OmegaConf.load(config_path)
        
        # ì •ê·œí™” ì„¤ì •
        self.normalize_twist = normalize_twist
        if normalize_twist:
            self.twist_normalizer = TwistNormalizer(stats_path=normalization_stats_path)
            print(f"âœ… Twist ì—­ì •ê·œí™” í™œì„±í™”: {normalization_stats_path}")
            print(self.twist_normalizer.get_stats_summary())
        else:
            self.twist_normalizer = None
            print("âš ï¸ Twist ì—­ì •ê·œí™” ë¹„í™œì„±í™”")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        self.model.eval()
        
        print(f"âœ… Normalized Motion RCFM Inference Engine loaded on {self.device}")
        print(f"ğŸ“Š Model config: {self.config.model.arch}")
    
    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        model = get_model(self.config.model)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        if Path(model_path).exists():
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            # ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ í˜•íƒœ ì§€ì›
            if 'model_state' in checkpoint:
                model.load_state_dict(checkpoint['model_state'])
                print(f"âœ… Model loaded from model_state: {model_path}")
            elif 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
                print(f"âœ… Model loaded from checkpoint: {model_path}")
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
                print(f"âœ… Model loaded from state dict: {model_path}")
            else:
                model.load_state_dict(checkpoint)
                print(f"âœ… Model loaded directly: {model_path}")
        else:
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        return model.to(self.device)
    
    def load_pointcloud(self, pc_path: str, num_points: int = 2000) -> torch.Tensor:
        """í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë¡œë“œ (PLY/OBJ ì§€ì›)"""
        try:
            if pc_path.endswith('.ply'):
                pcd = o3d.io.read_point_cloud(pc_path)
                points = np.asarray(pcd.points)
            elif pc_path.endswith('.obj'):
                # OBJ íŒŒì¼ì—ì„œ ì •ì  ì¶”ì¶œ
                points = []
                with open(pc_path, 'r') as f:
                    for line in f:
                        if line.startswith('v '):
                            _, x, y, z = line.strip().split()
                            points.append([float(x), float(y), float(z)])
                points = np.array(points)
            else:
                raise ValueError(f"Unsupported point cloud format: {pc_path}")
            
            # í¬ì¸íŠ¸ ê°œìˆ˜ ì¡°ì •
            if len(points) > num_points:
                indices = np.random.choice(len(points), num_points, replace=False)
                points = points[indices]
            elif len(points) < num_points:
                indices = np.random.choice(len(points), num_points, replace=True)
                points = points[indices]
            
            return torch.FloatTensor(points)
            
        except Exception as e:
            print(f"âŒ Error loading point cloud {pc_path}: {e}")
            # ë”ë¯¸ í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë°˜í™˜
            return torch.randn(num_points, 3)
    
    @torch.no_grad()
    def generate_trajectory(self, 
                          pointcloud: torch.Tensor,
                          start_pose: np.ndarray,
                          target_pose: np.ndarray,
                          num_samples: int = 20,
                          ode_steps: int = 20) -> Dict[str, Union[np.ndarray, List]]:
        """
        ê¶¤ì  ìƒì„± (ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì ìš©)
        
        Args:
            pointcloud: [N, 3] í™˜ê²½ í¬ì¸íŠ¸í´ë¼ìš°ë“œ
            start_pose: [4, 4] ì‹œì‘ SE(3) pose
            target_pose: [4, 4] ëª©í‘œ SE(3) pose  
            num_samples: ìƒì„±í•  ì›¨ì´í¬ì¸íŠ¸ ìˆ˜
            ode_steps: ODE solver ìŠ¤í… ìˆ˜
            
        Returns:
            Dict with 'poses': [num_samples, 4, 4], 'success': bool, etc.
        """
        start_time = time.time()
        
        # ì…ë ¥ ê²€ì¦
        assert pointcloud.shape[1] == 3, f"Expected [N, 3] pointcloud, got {pointcloud.shape}"
        assert start_pose.shape == (4, 4), f"Expected [4, 4] start pose, got {start_pose.shape}"
        assert target_pose.shape == (4, 4), f"Expected [4, 4] target pose, got {target_pose.shape}"
        
        # GPUë¡œ ì´ë™
        pointcloud = pointcloud.to(self.device)
        start_pose_torch = torch.FloatTensor(start_pose).to(self.device)
        target_pose_torch = torch.FloatTensor(target_pose).to(self.device)
        
        try:
            # Point cloud íŠ¹ì§• ì¶”ì¶œ
            pc_batch = pointcloud.unsqueeze(0).transpose(2, 1)  # [1, 3, N]
            pc_features = self.model.get_latent_vector(pc_batch)  # [1, feat_dim]
            
            # CFM ìƒ˜í”Œë§ (ode_stepsëŠ” ëª¨ë¸ ë‚´ë¶€ì—ì„œ self.ode_steps ì‚¬ìš©)
            generated_poses, nfe_counts = self.model.sample(
                num_samples=num_samples,
                pc=pc_batch
            )
            
            # [num_samples, 4, 4]ë¡œ ë³€í™˜
            if generated_poses.dim() == 3:
                trajectory_poses = generated_poses.cpu().numpy()
            else:
                trajectory_poses = generated_poses.view(num_samples, 4, 4).cpu().numpy()
            
            # ì‹œì‘ê³¼ ëì  ì¡°ì • (ì„ íƒì )
            trajectory_poses[0] = start_pose
            trajectory_poses[-1] = target_pose
            
            inference_time = time.time() - start_time
            
            return {
                'poses': trajectory_poses,
                'success': True,
                'inference_time': inference_time,
                'num_samples': num_samples,
                'start_pose': start_pose,
                'target_pose': target_pose
            }
            
        except Exception as e:
            print(f"âŒ Trajectory generation failed: {e}")
            return {
                'poses': None,
                'success': False,
                'error': str(e),
                'inference_time': time.time() - start_time
            }
    
    def denormalize_trajectory(self, trajectory_result: Dict) -> Dict:
        """ê¶¤ì  ì—­ì •ê·œí™” (ì¶”í›„ í•„ìš”ì‹œ êµ¬í˜„)"""
        # v2ì—ì„œëŠ” SE(3) ì§ì ‘ ìƒì„±í•˜ë¯€ë¡œ ë³„ë„ ì—­ì •ê·œí™” ë¶ˆí•„ìš”
        return trajectory_result
    
    def visualize_trajectory(self, trajectory_result: Dict, save_path: Optional[str] = None):
        """ê¶¤ì  ì‹œê°í™” (ê°„ë‹¨í•œ ì¶œë ¥)"""
        if not trajectory_result['success']:
            print(f"âŒ Cannot visualize failed trajectory: {trajectory_result.get('error', 'Unknown error')}")
            return
        
        poses = trajectory_result['poses']
        print(f"ğŸ“Š Generated trajectory with {len(poses)} poses")
        print(f"â±ï¸ Inference time: {trajectory_result['inference_time']:.3f}s")
        
        # ìœ„ì¹˜ ë³€í™”ëŸ‰ ê³„ì‚°
        positions = poses[:, :3, 3]
        distances = np.linalg.norm(np.diff(positions, axis=0), axis=1)
        total_distance = np.sum(distances)
        
        print(f"ğŸ“ Total distance: {total_distance:.3f}")
        print(f"ğŸ“ Average step size: {np.mean(distances):.3f}")
        print(f"ğŸ¯ Start position: {positions[0]}")
        print(f"ğŸ End position: {positions[-1]}")
    
    def save_trajectory_json(self,
                           trajectory_poses: np.ndarray,
                           start_pose: np.ndarray,
                           goal_pose: np.ndarray,
                           environment_name: str = "inferred_env",
                           rigid_body_id: int = 3,
                           rigid_body_type: str = "elongated_ellipse",
                           output_path: str = None) -> str:
        """
        ì¶”ë¡ ëœ ê¶¤ì ì„ ê¸°ì¡´ ì‹œê°í™” ì½”ë“œì™€ í˜¸í™˜ë˜ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
        
        Args:
            trajectory_poses: [N, 4, 4] SE(3) ë³€í™˜ í–‰ë ¬ë“¤
            start_pose: [4, 4] ì‹œì‘ SE(3) í¬ì¦ˆ
            goal_pose: [4, 4] ëª©í‘œ SE(3) í¬ì¦ˆ  
            environment_name: í™˜ê²½ ì´ë¦„
            rigid_body_id: Rigid body ID (0-3)
            rigid_body_type: Rigid body íƒ€ì…
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        
        # SE(3) í–‰ë ¬ì„ 6D í¬ì¦ˆë¡œ ë³€í™˜
        def se3_to_6d_pose(se3_matrix):
            """SE(3) 4x4 í–‰ë ¬ì„ [x, y, z, roll, pitch, yaw] 6D í¬ì¦ˆë¡œ ë³€í™˜"""
            from scipy.spatial.transform import Rotation
            
            # í‰í–‰ì´ë™ ë²¡í„° ì¶”ì¶œ
            translation = se3_matrix[:3, 3]
            
            # íšŒì „ í–‰ë ¬ ì¶”ì¶œ ë° ì˜¤ì¼ëŸ¬ê° ë³€í™˜
            rotation_matrix = se3_matrix[:3, :3]
            rotation = Rotation.from_matrix(rotation_matrix)
            euler_angles = rotation.as_euler('xyz', degrees=False)  # [roll, pitch, yaw]
            
            return [float(translation[0]), float(translation[1]), float(translation[2]), 
                   float(euler_angles[0]), float(euler_angles[1]), float(euler_angles[2])]
        
        # ê¶¤ì  ë°ì´í„°ë¥¼ 6D í¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        trajectory_6d = []
        for pose_matrix in trajectory_poses:
            pose_6d = se3_to_6d_pose(pose_matrix)
            trajectory_6d.append(pose_6d)
        
        # ì‹œì‘/ëª©í‘œ í¬ì¦ˆë„ 6Dë¡œ ë³€í™˜
        start_6d = se3_to_6d_pose(start_pose)
        goal_6d = se3_to_6d_pose(goal_pose)
        
        # ê¶¤ì  ID ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        trajectory_id = f"inferred_traj_rb{rigid_body_id}_{timestamp}"
        
        # JSON ë°ì´í„° êµ¬ì¡° ìƒì„± (ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜)
        trajectory_data = {
            "pair_id": 0,
            "trajectory_id": trajectory_id,
            "rigid_body": {
                "id": rigid_body_id,
                "type": rigid_body_type
            },
            "environment": {
                "name": environment_name,
                "ply_file": f"../../../data/pointcloud/circle_envs_10k/{environment_name}.ply"
            },
            "start_pose": start_6d,
            "goal_pose": goal_6d,
            "path": {
                "data": trajectory_6d
            },
            "metadata": {
                "generated_by": "v2_motion_rcfm_inference",
                "timestamp": timestamp,
                "num_poses": len(trajectory_6d),
                "model_config": self.config.model.arch if hasattr(self.config, 'model') else "motion_rcfm"
            }
        }
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        if output_path is None:
            output_dir = Path("inference_results")
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"{trajectory_id}.json"
        else:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # JSON íŒŒì¼ ì €ì¥
        with open(output_path, 'w') as f:
            json.dump(trajectory_data, f, indent=2)
        
        print(f"ğŸ’¾ ê¶¤ì  JSON ì €ì¥ë¨: {output_path}")
        print(f"   ğŸ“Š í¬ì¦ˆ ê°œìˆ˜: {len(trajectory_6d)}")
        print(f"   ğŸ¯ ì‹œì‘ ìœ„ì¹˜: [{start_6d[0]:.3f}, {start_6d[1]:.3f}, {start_6d[5]:.3f}Â°]")
        print(f"   ğŸ ëª©í‘œ ìœ„ì¹˜: [{goal_6d[0]:.3f}, {goal_6d[1]:.3f}, {goal_6d[5]:.3f}Â°]")
        
        return str(output_path)

def test_inference():
    """ì¶”ë¡  í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª Testing v2 Normalized Motion RCFM Inference...")
    
    # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
    checkpoint_patterns = [
        "train_results/motion_rcfm/*/best_model.pth",
        "train_results/motion_rcfm/*/model_latest.pth",
        "train_results/motion_rcfm/*/*.pth"
    ]
    
    checkpoints = []
    for pattern in checkpoint_patterns:
        checkpoints.extend(glob.glob(pattern))
        if checkpoints:
            break
    
    if not checkpoints:
        print("âŒ No trained model found. Please train a model first.")
        return
    
    latest_checkpoint = max(checkpoints, key=lambda x: Path(x).stat().st_mtime)
    print(f"ğŸ“¦ Using checkpoint: {latest_checkpoint}")
    
    # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
    inference_engine = NormalizedMotionRCFMInference(
        model_path=latest_checkpoint,
        config_path="configs/motion_rcfm.yml",
        normalize_twist=True
    )
    
    # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    print("\nğŸ¯ Testing with dummy data...")
    
    # ë”ë¯¸ í¬ì¸íŠ¸í´ë¼ìš°ë“œ
    pointcloud = torch.randn(2000, 3)
    
    # ë”ë¯¸ ì‹œì‘/ëª©í‘œ pose
    start_pose = np.eye(4)
    target_pose = np.eye(4)
    target_pose[:3, 3] = [1.0, 1.0, 0.0]  # 1m x, 1m y ì´ë™
    
    # ê¶¤ì  ìƒì„±
    result = inference_engine.generate_trajectory(
        pointcloud=pointcloud,
        start_pose=start_pose,
        target_pose=target_pose,
        num_samples=20
    )
    
    # ê²°ê³¼ ì¶œë ¥
    inference_engine.visualize_trajectory(result)
    
    if result['success']:
        print("âœ… Inference test successful!")
        
        # ê¶¤ì ì„ JSON íŒŒì¼ë¡œ ì €ì¥ í…ŒìŠ¤íŠ¸
        print("\nğŸ’¾ Testing trajectory JSON export...")
        try:
            saved_path = inference_engine.save_trajectory_json(
                trajectory_poses=result['poses'],
                start_pose=result['start_pose'],
                goal_pose=result['target_pose'],
                environment_name="test_environment",
                rigid_body_id=3,
                rigid_body_type="elongated_ellipse"
            )
            print(f"âœ… ê¶¤ì  ì €ì¥ ì„±ê³µ! íŒŒì¼: {saved_path}")
            print(f"ğŸ“ ê¸°ì¡´ ì‹œê°í™” ì½”ë“œë¡œ ì‚¬ìš© ê°€ëŠ¥:")
            print(f"   python packages/data_generator/reference_planner/utils/trajectory_visualizer.py {saved_path} --mode static")
        except Exception as e:
            print(f"âŒ ê¶¤ì  ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("âŒ Inference test failed!")

if __name__ == "__main__":
    test_inference()
