import torch
import os
import numpy as np
import json
import h5py
from torch.utils.data import Dataset
from scipy.spatial.transform import Rotation
import glob
import open3d as o3d
from copy import deepcopy
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.motion_utils import twist_to_se3_matrix
from utils.normalization import TwistNormalizer


class MotionDataset4RCFM(torch.utils.data.Dataset):
    """
    Dual-format Motion Planning Dataset for RCFM
    - Trajectories: JSON + H5 support (auto-detection)
    - Point clouds: PLY + OBJ support (auto-detection)
    - fm-main style structure with motion planning data
    """
    
    def __init__(self,
                 trajectory_root,
                 pointcloud_root,
                 split='train',
                 max_trajectories=None,
                 use_bsplined=True,
                 num_point_cloud=2000,
                 num_twists=1000,  # fm-mainì˜ num_graspsì™€ ë™ì¼í•œ ì—­í• 
                 scale=1.0,
                 augmentation=True,
                 normalize_twist=True,
                 normalization_stats_path="configs/normalization_stats.json",
                 **kwargs):
        
        self.trajectory_root = trajectory_root
        self.pointcloud_root = pointcloud_root
        self.split = split
        self.max_trajectories = max_trajectories
        self.use_bsplined = use_bsplined
        self.num_point_cloud = num_point_cloud
        self.num_twists = num_twists
        self.scale = scale
        self.augmentation = augmentation and (split == 'train')
        
        # ì •ê·œí™” ì„¤ì •
        self.normalize_twist = normalize_twist
        if normalize_twist:
            try:
                self.normalizer = TwistNormalizer(normalization_stats_path)
                print(f"âœ… ì •ê·œí™” í™œì„±í™”: {normalization_stats_path}")
            except:
                print(f"âš ï¸ ì •ê·œí™” í†µê³„ íŒŒì¼ ì—†ìŒ, ì •ê·œí™” ë¹„í™œì„±í™”")
                self.normalize_twist = False
                self.normalizer = None
        else:
            self.normalizer = None
            print("ğŸ“ ì •ê·œí™” ë¹„í™œì„±í™”")
        
        print(f"ğŸš€ MotionDataset4RCFM init - split: {split}")
        
        # ê¶¤ì  ë°ì´í„° ìˆ˜ì§‘
        self.trajectory_files = self._collect_trajectory_files()
        print(f"ğŸ“ Found {len(self.trajectory_files)} trajectory files")
        
        # ìƒ˜í”Œ ìƒì„±
        self.samples = self._create_samples()
        print(f"ğŸ“Š Created {len(self.samples)} samples")
        
        # CFMì„ ìœ„í•œ ê·¸ë£¹í•‘ (í™˜ê²½ë³„)
        self._group_samples_by_env()
        print(f"ğŸ—‚ï¸ Grouped into {len(self.env_groups)} environments")
    
    def _collect_trajectory_files(self):
        """ê¶¤ì  íŒŒì¼ ìˆ˜ì§‘ (JSON + H5 ìë™ ê°ì§€)"""
        files = []
        
        # JSON íŒŒì¼ íŒ¨í„´
        if self.use_bsplined:
            json_pattern = os.path.join(self.trajectory_root, "*_bsplined.json")
        else:
            json_pattern = os.path.join(self.trajectory_root, "*_traj_rb3.json")
        
        json_files = sorted(glob.glob(json_pattern))
        
        # H5 íŒŒì¼ íŒ¨í„´ (fm-main í˜¸í™˜)
        h5_pattern = os.path.join(self.trajectory_root, "*.h5")
        h5_files = sorted(glob.glob(h5_pattern))
        
        # íŒŒì¼ í˜•ì‹ ìš°ì„ ìˆœìœ„: JSON > H5
        files = json_files + h5_files
        
        if self.max_trajectories:
            files = files[:self.max_trajectories]
        
        print(f"ğŸ“ Found {len(json_files)} JSON + {len(h5_files)} H5 trajectory files")
        return files
    
    def _load_h5_trajectory(self, h5_file):
        """H5 ê¶¤ì  íŒŒì¼ ë¡œë”© (fm-main í˜¸í™˜)"""
        try:
            with h5py.File(h5_file, 'r') as f:
                # fm-main H5 êµ¬ì¡° ì¶”ì •
                if 'poses' in f and 'timestamps' in f:
                    poses = f['poses'][:]  # [N, 4, 4] SE(3) matrices
                    timestamps = f['timestamps'][:]  # [N] timestamps
                elif 'trajectory' in f:
                    traj_group = f['trajectory']
                    poses = traj_group['poses'][:]
                    timestamps = traj_group['timestamps'][:]
                else:
                    # ê¸°ë³¸ êµ¬ì¡° ì‹œë„
                    keys = list(f.keys())
                    print(f"âš ï¸ Unknown H5 structure in {h5_file}, keys: {keys}")
                    return None
                
                # í™˜ê²½ ID ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
                env_id = os.path.basename(h5_file).replace('.h5', '')
                
                return {
                    'poses': poses,
                    'timestamps': timestamps,
                    'env_id': env_id
                }
                
        except Exception as e:
            print(f"âŒ Error loading H5 file {h5_file}: {e}")
            return None
    
    def _detect_pointcloud_file(self, env_id):
        """í¬ì¸íŠ¸í´ë¼ìš°ë“œ íŒŒì¼ ìë™ ê°ì§€ (PLY -> OBJ ìˆœì„œ)"""
        # PLY ìš°ì„  ì‹œë„
        ply_file = os.path.join(self.pointcloud_root, f"{env_id}.ply")
        if os.path.exists(ply_file):
            return ply_file, 'ply'
        
        # OBJ ì‹œë„
        obj_file = os.path.join(self.pointcloud_root, f"{env_id}.obj")
        if os.path.exists(obj_file):
            return obj_file, 'obj'
        
        # ë‘˜ ë‹¤ ì—†ìŒ
        print(f"âš ï¸ No pointcloud found for {env_id} (checked .ply and .obj)")
        return None, None
    
    def _create_samples(self):
        """CFMìš© twist vector ìƒ˜í”Œ ìƒì„± (JSON + H5 ì§€ì›)"""
        samples = []
        
        for traj_file in self.trajectory_files:
            try:
                # íŒŒì¼ í˜•ì‹ ê°ì§€
                if traj_file.endswith('.json'):
                    # JSON íŒŒì¼ ì²˜ë¦¬
                    with open(traj_file, 'r') as f:
                        traj_data = json.load(f)
                    
                    # í™˜ê²½ ì •ë³´
                    env_name = traj_data.get('environment', {}).get('name', 'unknown')
                    env_id = env_name
                    pair_id = traj_data.get('pair_id', 0)
                    
                    # ê¶¤ì  ë°ì´í„° íŒŒì‹±
                    waypoints = self._parse_trajectory(traj_data)
                    
                elif traj_file.endswith('.h5'):
                    # H5 íŒŒì¼ ì²˜ë¦¬
                    h5_data = self._load_h5_trajectory(traj_file)
                    if h5_data is None:
                        continue
                    
                    env_id = h5_data['env_id']
                    pair_id = 0
                    
                    # H5ì—ì„œ waypoint ë³€í™˜
                    waypoints = []
                    for i, (pose, timestamp) in enumerate(zip(h5_data['poses'], h5_data['timestamps'])):
                        waypoints.append({
                            'pose': pose,
                            'timestamp': timestamp
                        })
                
                else:
                    print(f"âš ï¸ Unsupported trajectory format: {traj_file}")
                    continue
                
                if len(waypoints) < 2:
                    continue
                
                # í¬ì¸íŠ¸í´ë¼ìš°ë“œ íŒŒì¼ ìë™ ê°ì§€
                pc_file, pc_format = self._detect_pointcloud_file(env_id)
                if pc_file is None:
                    continue
                
                # ê° waypointì—ì„œ twist vector ì¶”ì¶œ
                twist_vectors = []
                target_poses = []
                
                for i, waypoint in enumerate(waypoints):
                    # ëª©í‘œ twist vector (CFMì˜ x1 ì—­í• )
                    if i < len(waypoints) - 1:
                        next_wp = waypoints[i + 1]
                        dt = next_wp['timestamp'] - waypoint['timestamp']
                        if dt <= 0:
                            dt = 0.1
                        
                        twist = self._compute_twist_vector(
                            waypoint['pose'], next_wp['pose'], dt
                        )
                    else:
                        twist = np.zeros(6)  # ì •ì§€
                    
                    twist_vectors.append(twist)
                    target_poses.append(waypoints[-1]['pose'])  # ìµœì¢… ëª©í‘œ pose
                
                # ìƒ˜í”Œ ì €ì¥ (fm-main ìŠ¤íƒ€ì¼)
                sample = {
                    'env_id': env_id,
                    'pc_file': pc_file,
                    'pc_format': pc_format,  # í¬ì¸íŠ¸í´ë¼ìš°ë“œ í˜•ì‹ ì •ë³´
                    'twist_vectors': np.array(twist_vectors),  # [N, 6] - CFM íƒ€ê²Ÿ
                    'target_poses': np.array(target_poses),    # [N, 4, 4] - ì¡°ê±´
                    'traj_file': traj_file,
                    'traj_format': 'json' if traj_file.endswith('.json') else 'h5'
                }
                
                samples.append(sample)
                
            except Exception as e:
                print(f"âŒ Error processing {traj_file}: {e}")
                continue
        
        return samples
    
    def _parse_trajectory(self, traj_data):
        """JSON ê¶¤ì  â†’ waypoint ë¦¬ìŠ¤íŠ¸"""
        path_data = traj_data.get('path', {})
        timestamps = path_data.get('timestamps', [])
        poses_flat = path_data.get('data', [])
        
        waypoints = []
        num_waypoints = min(len(timestamps), len(poses_flat))
        
        for i in range(num_waypoints):
            timestamp = timestamps[i] if i < len(timestamps) else 0.0
            pose_6d = poses_flat[i]
            
            if len(pose_6d) >= 6:
                x, y, z, rx, ry, rz = pose_6d[:6]
                
                # SE(3) í–‰ë ¬ ìƒì„±
                R = Rotation.from_rotvec([rx, ry, rz]).as_matrix()
                pose_matrix = np.eye(4)
                pose_matrix[:3, :3] = R
                pose_matrix[:3, 3] = [x, y, z]
                
                waypoints.append({
                    'pose': pose_matrix,
                    'timestamp': timestamp
                })
        
        return waypoints
    
    def _compute_twist_vector(self, T1, T2, dt):
        """SE(3) pose ê°„ twist vector ê³„ì‚° (body frame)"""
        # Translation (body frame)
        R1 = T1[:3, :3]
        p1, p2 = T1[:3, 3], T2[:3, 3]
        v_body = R1.T @ (p2 - p1) / dt
        
        # Rotation (body frame) 
        R2 = T2[:3, :3]
        R_rel = R1.T @ R2
        r_rel = Rotation.from_matrix(R_rel)
        w_body = r_rel.as_rotvec() / dt
        
        return np.concatenate([w_body, v_body])  # [Ï‰, v]
    
    def _group_samples_by_env(self):
        """í™˜ê²½ë³„ ìƒ˜í”Œ ê·¸ë£¹í•‘ (CFMì„ ìœ„í•œ ë°°ì¹˜ êµ¬ì„±)"""
        self.env_groups = {}
        for i, sample in enumerate(self.samples):
            env_id = sample['env_id']
            if env_id not in self.env_groups:
                self.env_groups[env_id] = []
            self.env_groups[env_id].append(i)
        
        self.env_list = list(self.env_groups.keys())
    
    def __len__(self):
        return len(self.env_list)  # í™˜ê²½ ë‹¨ìœ„ë¡œ iterate
    
    def __getitem__(self, index):
        """fm-main ìŠ¤íƒ€ì¼ ë°°ì¹˜ ë°˜í™˜"""
        env_id = self.env_list[index]
        sample_indices = self.env_groups[env_id]
        
        # í™˜ê²½ì˜ ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ
        main_sample = self.samples[sample_indices[0]]
        
        # í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë¡œë”© (ì•ˆì „, ìë™ í˜•ì‹ ê°ì§€)
        pc = self._load_pointcloud_safe(main_sample['pc_file'], pc_format='auto')
        
        # twist vectors ìƒ˜í”Œë§ (CFM x1 ì—­í• )
        twist_vectors = main_sample['twist_vectors']
        target_poses = main_sample['target_poses']
        
        # ìƒ˜í”Œ ê°œìˆ˜ ì¡°ì •
        if len(twist_vectors) > self.num_twists:
            indices = np.random.choice(len(twist_vectors), self.num_twists, replace=False)
        else:
            indices = np.random.choice(len(twist_vectors), self.num_twists, replace=True)
        
        selected_twists = twist_vectors[indices]
        selected_targets = target_poses[indices]
        
        # Twist ì •ê·œí™” ì ìš© (CFM í›ˆë ¨ìš©)
        if self.normalize_twist and self.normalizer is not None:
            selected_twists = self.normalizer.normalize_twist(selected_twists)
        
        # Twist vectorsë¥¼ SE(3) ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ë³€í™˜ (CFM í˜¸í™˜)
        selected_twists_torch = torch.FloatTensor(selected_twists)
        Ts_twist = twist_to_se3_matrix(selected_twists_torch).numpy()
        
        # fm-main í˜¸í™˜: [num_twists, 4, 4] í˜•íƒœë¡œ ìœ ì§€, íŒ¨ë”©ìœ¼ë¡œ num_twists ê°œ ë§ì¶¤
        # ìœ íš¨í•˜ì§€ ì•Šì€ graspëŠ” ë§ˆì§€ë§‰ í–‰ì´ [0,0,0,0]ì´ ë˜ë„ë¡ íŒ¨ë”©
        Ts_grasp_padded = np.zeros((self.num_twists, 4, 4))
        num_valid = min(len(Ts_twist), self.num_twists)
        
        if num_valid > 0:
            Ts_grasp_padded[:num_valid] = Ts_twist[:num_valid]
            # ìœ íš¨í•œ SE(3) í–‰ë ¬ì€ ë§ˆì§€ë§‰ í–‰ì´ [0,0,0,1]
            Ts_grasp_padded[:num_valid, 3, 3] = 1.0
        
        # ë””ë²„ê¹…: ì‹¤ì œë¡œëŠ” ëª¨ë“  twistë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì œí•œ
        # CFM í›ˆë ¨ì—ì„œëŠ” ë„ˆë¬´ ë§ì€ targetì´ ìˆìœ¼ë©´ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŒ
        max_valid_twists = min(100, num_valid)  # ìµœëŒ€ 100ê°œë§Œ ìœ íš¨í•˜ê²Œ ì„¤ì •
        if max_valid_twists < self.num_twists:
            # 100ê°œ ì´í›„ëŠ” ë¬´íš¨í•œ SE(3)ë¡œ ì„¤ì • (ë§ˆì§€ë§‰ í–‰ì´ [0,0,0,0])
            Ts_grasp_padded[max_valid_twists:, 3, 3] = 0.0
        
        return {
            'pc': torch.FloatTensor(pc),
            'Ts_grasp': torch.FloatTensor(Ts_grasp_padded),  # [num_twists, 4, 4] fm-main í˜¸í™˜
            'target_poses': torch.FloatTensor(selected_targets),
            'env_id': env_id
        }
    
    def _load_obj_pointcloud(self, obj_file):
        """OBJ íŒŒì¼ì—ì„œ í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë¡œë”© (fm-main í˜¸í™˜)"""
        vertices = []
        try:
            with open(obj_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith('v '):  # vertex line
                        parts = line.split()
                        if len(parts) >= 4:
                            x, y, z = float(parts[1]), float(parts[2]), float(parts[3])
                            vertices.append([x, y, z])
            
            if len(vertices) == 0:
                print(f"âš ï¸ No vertices found in OBJ file: {obj_file}")
                return self._generate_fallback_pointcloud()
            
            return np.array(vertices, dtype=np.float32)
            
        except Exception as e:
            print(f"âŒ OBJ loading failed: {obj_file}, error: {e}")
            return self._generate_fallback_pointcloud()
    
    def _load_pointcloud_safe(self, pc_file, pc_format='auto'):
        """ì•ˆì „í•œ í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë¡œë”© (PLY + OBJ ì§€ì›)"""
        try:
            # í˜•ì‹ ìë™ ê°ì§€
            if pc_format == 'auto':
                if pc_file.endswith('.ply'):
                    pc_format = 'ply'
                elif pc_file.endswith('.obj'):
                    pc_format = 'obj'
                else:
                    print(f"âš ï¸ Unknown pointcloud format: {pc_file}")
                    return self._generate_fallback_pointcloud()
            
            # í˜•ì‹ë³„ ë¡œë”©
            if pc_format == 'ply':
                o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)
                mesh = o3d.io.read_triangle_mesh(pc_file)
                points = np.asarray(mesh.vertices)
            elif pc_format == 'obj':
                points = self._load_obj_pointcloud(pc_file)
            else:
                raise ValueError(f"Unsupported format: {pc_format}")
            
            if len(points) == 0:
                points = self._generate_fallback_pointcloud()
            
            # ìŠ¤ì¼€ì¼ë§
            if self.scale != 1.0:
                points *= self.scale
            
            # í¬ì¸íŠ¸ ìˆ˜ ì¡°ì •
            if len(points) > self.num_point_cloud:
                indices = np.random.choice(len(points), self.num_point_cloud, replace=False)
                points = points[indices]
            elif len(points) < self.num_point_cloud:
                indices = np.random.choice(len(points), self.num_point_cloud, replace=True)
                points = points[indices]
            
            # ë°ì´í„° ì¦ê°•
            if self.augmentation:
                points = self._augment_pointcloud(points)
            
            return points.astype(np.float32)
            
        except Exception as e:
            print(f"âŒ PC loading failed: {pc_file} ({pc_format}), error: {e}")
            return self._generate_fallback_pointcloud()
    
    def _generate_fallback_pointcloud(self):
        """ëŒ€ì²´ í¬ì¸íŠ¸í´ë¼ìš°ë“œ ìƒì„±"""
        # ì›í˜• í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
        angles = np.linspace(0, 2*np.pi, self.num_point_cloud//2)
        outer_x = 3.0 * np.cos(angles)
        outer_y = 3.0 * np.sin(angles)
        outer_z = np.zeros_like(outer_x)
        
        # ë‚´ë¶€ ì¥ì• ë¬¼
        inner_x = np.random.uniform(-2, 2, self.num_point_cloud//2)
        inner_y = np.random.uniform(-2, 2, self.num_point_cloud//2)
        inner_z = np.random.uniform(0, 1, self.num_point_cloud//2)
        
        points = np.vstack([
            np.column_stack([outer_x, outer_y, outer_z]),
            np.column_stack([inner_x, inner_y, inner_z])
        ])
        
        return points.astype(np.float32)
    
    def _augment_pointcloud(self, pointcloud):
        """í¬ì¸íŠ¸í´ë¼ìš°ë“œ ì¦ê°•"""
        # Zì¶• íšŒì „
        angle = np.random.uniform(0, 2 * np.pi)
        cos_a, sin_a = np.cos(angle), np.sin(angle)
        R = np.array([[cos_a, -sin_a, 0],
                     [sin_a, cos_a, 0],
                     [0, 0, 1]])
        
        pointcloud = (R @ pointcloud.T).T
        
        # ë…¸ì´ì¦ˆ
        noise = np.random.normal(0, 0.01, pointcloud.shape)
        pointcloud += noise
        
        return pointcloud