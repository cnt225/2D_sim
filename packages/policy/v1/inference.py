#!/usr/bin/env python3
"""
Motion RFM ì¶”ë¡  ì—”ì§„
SE(3) Rigid Body Motion Planningì„ ìœ„í•œ Riemannian Flow Matching ê¸°ë°˜ ê¶¤ì  ìƒì„±ê¸°
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path
import time

from models import get_model
from utils.Lie import *
# from utils.pointcloud import load_pointcloud
from omegaconf import OmegaConf
from utils.normalization import TwistNormalizer


class MotionRFMInference:
    """Motion RFM ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self, model_path: str, config_path: str, device: str = 'cuda'):
        """
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            config_path: ëª¨ë¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ  
            device: ì—°ì‚° ë””ë°”ì´ìŠ¤ ('cuda' or 'cpu')
        """
        self.device = torch.device(device)
        self.config = OmegaConf.load(config_path)
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        self.model.eval()
        
        # ê¸°ë³¸ ì„¤ì •
        self.default_config = {
            'dt': 0.02,                    # ì ë¶„ íƒ€ì„ìŠ¤í…
            'max_steps': 100,              # ìµœëŒ€ ë°˜ë³µ ìˆ˜
            'pos_tolerance': 0.02,         # ìœ„ì¹˜ í—ˆìš© ì˜¤ì°¨ (m)
            'rot_tolerance': 0.1,          # íšŒì „ í—ˆìš© ì˜¤ì°¨ (rad)
            'early_stop': True,            # ì¡°ê¸° ì¢…ë£Œ í™œì„±í™”
            'safety_check': True,          # ì•ˆì „ ì²´í¬ í™œì„±í™”
            'max_divergence': 2.0,         # ë°œì‚° ê°ì§€ ë°°ìˆ˜
        }
        
        print(f"âœ… Motion RFM Inference Engine loaded on {device}")
        print(f"ğŸ“Š Model config: {self.config.model.arch}")
    
    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        model = get_model(self.config.model)
        
        if Path(model_path).exists():
            # PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ì‚¬ìš©
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… Model loaded from {model_path}")
        else:
            print(f"âš ï¸ Checkpoint not found: {model_path}, using random weights")
        
        return model.to(self.device)
    
    def generate_trajectory(self, 
                          start_pose: Union[torch.Tensor, np.ndarray],
                          target_pose: Union[torch.Tensor, np.ndarray], 
                          pointcloud: Union[torch.Tensor, np.ndarray],
                          config: Optional[Dict] = None) -> Dict:
        """
        ê¶¤ì  ìƒì„± ë©”ì¸ í•¨ìˆ˜
        
        Args:
            start_pose: ì‹œì‘ SE(3) í¬ì¦ˆ (4x4 matrix)
            target_pose: ëª©í‘œ SE(3) í¬ì¦ˆ (4x4 matrix)
            pointcloud: í™˜ê²½ í¬ì¸íŠ¸í´ë¼ìš°ë“œ (Nx3)
            config: ìƒì„± ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            
        Returns:
            Dict containing:
                - trajectory: List[torch.Tensor] - SE(3) í¬ì¦ˆ ì‹œí€€ìŠ¤
                - success: bool - ëª©í‘œ ë„ë‹¬ ì„±ê³µ ì—¬ë¶€
                - steps: int - ì‚¬ìš©ëœ ìŠ¤í… ìˆ˜
                - final_error: Dict - ìµœì¢… ì˜¤ì°¨ ì •ë³´
                - generation_time: float - ìƒì„± ì‹œê°„ (ì´ˆ)
                - info: Dict - ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
        """
        start_time = time.time()
        
        # ì„¤ì • ë³‘í•©
        cfg = {**self.default_config, **(config or {})}
        
        # ì…ë ¥ ì „ì²˜ë¦¬
        start_pose = self._to_tensor(start_pose)
        target_pose = self._to_tensor(target_pose)
        pointcloud = self._to_tensor(pointcloud)
        
        # ì´ˆê¸°í™”
        current_pose = start_pose.clone()
        trajectory = [current_pose.clone().cpu()]
        step = 0
        
        # ì´ˆê¸° ê±°ë¦¬ ê³„ì‚° (ë°œì‚° ê°ì§€ìš©)
        initial_distance = self._pose_distance(start_pose, target_pose)
        
        # ë©”ì¸ ìƒì„± ë£¨í”„
        with torch.no_grad():
            while step < cfg['max_steps']:
                # 1. Progress ê³„ì‚°
                progress = self._calculate_progress(current_pose, start_pose, target_pose)
                
                # 2. ëª¨ë¸ ì¶”ë¡ : 6D twist vector ì˜ˆì¸¡
                twist_6d = self._predict_twist(current_pose, target_pose, progress, pointcloud)
                
                # 3. ëª©í‘œ ë„ë‹¬ í™•ì¸ (ì¡°ê¸° ì¢…ë£Œ)
                if cfg['early_stop'] and self._reached_target(current_pose, target_pose, cfg):
                    break
                
                # 4. ì•ˆì „ ì²´í¬
                if cfg['safety_check'] and self._safety_check(current_pose, target_pose, 
                                                            initial_distance, cfg):
                    print(f"âš ï¸ Safety check failed at step {step}")
                    break
                
                # 5. SE(3) ì ë¶„: twist â†’ next pose
                current_pose = self._integrate_se3(current_pose, twist_6d, cfg['dt'])
                
                # 6. ê¶¤ì ì— ì¶”ê°€
                trajectory.append(current_pose.clone().cpu())
                step += 1
        
        # ê²°ê³¼ ì •ë¦¬
        generation_time = time.time() - start_time
        success = self._reached_target(current_pose, target_pose, cfg)
        final_error = self._calculate_final_error(current_pose, target_pose)
        
        return {
            'trajectory': trajectory,
            'success': success,
            'steps': step,
            'final_error': final_error,
            'generation_time': generation_time,
            'info': {
                'config': cfg,
                'initial_distance': initial_distance.item(),
                'final_distance': self._pose_distance(current_pose, target_pose).item(),
                'avg_step_time': generation_time / max(step, 1),
            }
        }
    
    def _predict_twist(self, current_pose: torch.Tensor, target_pose: torch.Tensor,
                      progress: torch.Tensor, pointcloud: torch.Tensor) -> torch.Tensor:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 6D twist vector ì˜ˆì¸¡"""
        # ì…ë ¥ ì¤€ë¹„ (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
        current_T = current_pose.unsqueeze(0)  # (1, 4, 4)
        target_T = target_pose.unsqueeze(0)    # (1, 4, 4)
        time_t = progress.unsqueeze(0).unsqueeze(0)  # (1, 1)
        pc = pointcloud.unsqueeze(0)           # (1, N, 3)
        
        # í¬ì¸íŠ¸í´ë¼ìš°ë“œ íŠ¹ì§• ì¶”ì¶œ (DGCNN ì…ë ¥ í˜•ì‹: [B, 3, N])
        pc_dgcnn = pc.transpose(1, 2)  # (1, 3, N)
        v = self.model.latent_feature(pc_dgcnn)  # (1, latent_dim)
        
        # ëª¨ë¸ì˜ velocity field ì§ì ‘ í˜¸ì¶œ (ì •ê·œí™”ëœ ì¶œë ¥)
        normalized_twist = self.model.velocity_field(current_T, target_T, time_t, v)  # (1, 6)
        normalized_twist = normalized_twist.squeeze(0)  # (6,)
        
        # ì—­ì •ê·œí™” (ì •ê·œí™”ëœ ì¶œë ¥ â†’ ì‹¤ì œ twist)
        if self.twist_normalizer is not None:
            real_twist = self.twist_normalizer.denormalize_twist(normalized_twist)
            return real_twist
        else:
            return normalized_twist
    
    def _se3_to_12d(self, se3_matrix: torch.Tensor) -> torch.Tensor:
        """SE(3) 4x4 matrix â†’ 12D vector ë³€í™˜"""
        batch_size = se3_matrix.shape[0]
        result = torch.zeros(batch_size, 12, device=se3_matrix.device)
        
        # Rotation matrix (3x3) â†’ 9D vector
        result[:, :9] = se3_matrix[:, :3, :3].reshape(batch_size, 9)
        
        # Translation vector (3D)
        result[:, 9:12] = se3_matrix[:, :3, 3]
        
        return result
    
    def _calculate_progress(self, current: torch.Tensor, start: torch.Tensor, 
                          target: torch.Tensor) -> torch.Tensor:
        """ê±°ë¦¬ ê¸°ë°˜ progress ê³„ì‚°"""
        total_dist = self._pose_distance(start, target)
        current_dist = self._pose_distance(current, target)
        
        # progress = 1 - (current_distance / total_distance)
        progress = 1.0 - (current_dist / (total_dist + 1e-8))
        return torch.clamp(progress, 0.0, 1.0)
    
    def _pose_distance(self, pose1: torch.Tensor, pose2: torch.Tensor) -> torch.Tensor:
        """SE(3) í¬ì¦ˆ ê°„ ê±°ë¦¬ ê³„ì‚°"""
        # ìœ„ì¹˜ ê±°ë¦¬
        pos_dist = torch.norm(pose1[:3, 3] - pose2[:3, 3])
        
        # íšŒì „ ê±°ë¦¬ (Frobenius norm of rotation difference)
        rot_diff = pose1[:3, :3] - pose2[:3, :3]
        rot_dist = torch.norm(rot_diff, 'fro')
        
        # ê°€ì¤‘ í•© (ìœ„ì¹˜ì™€ íšŒì „ ìŠ¤ì¼€ì¼ ì¡°ì •)
        return pos_dist + 0.1 * rot_dist
    
    def _reached_target(self, current: torch.Tensor, target: torch.Tensor, 
                       config: Dict) -> bool:
        """ëª©í‘œ ë„ë‹¬ ì—¬ë¶€ íŒë³„"""
        pos_error = torch.norm(current[:3, 3] - target[:3, 3])
        rot_error = self._rotation_angle_between(current[:3, :3], target[:3, :3])
        
        return (pos_error < config['pos_tolerance']) and (rot_error < config['rot_tolerance'])
    
    def _rotation_angle_between(self, R1: torch.Tensor, R2: torch.Tensor) -> torch.Tensor:
        """ë‘ íšŒì „ í–‰ë ¬ ê°„ì˜ ê°ë„ ì°¨ì´ ê³„ì‚°"""
        # R_diff = R2^T @ R1
        R_diff = R2.T @ R1
        
        # traceë¥¼ ì´ìš©í•œ ê°ë„ ê³„ì‚°
        trace = torch.trace(R_diff)
        angle = torch.acos(torch.clamp((trace - 1) / 2, -1, 1))
        
        return angle
    
    def _safety_check(self, current: torch.Tensor, target: torch.Tensor,
                     initial_distance: torch.Tensor, config: Dict) -> bool:
        """ì•ˆì „ ì²´í¬ (ë°œì‚° ê°ì§€)"""
        current_distance = self._pose_distance(current, target)
        
        # ë°œì‚° ê°ì§€: ì´ˆê¸° ê±°ë¦¬ì˜ ë°°ìˆ˜ ì´ìƒ ë©€ì–´ì§€ë©´ ìœ„í—˜
        is_diverging = current_distance > initial_distance * config['max_divergence']
        
        return is_diverging
    
    def _integrate_se3(self, pose: torch.Tensor, twist_6d: torch.Tensor, 
                      dt: float) -> torch.Tensor:
        """SE(3) exponential mapì„ ì´ìš©í•œ ì ë¶„"""
        # twist_6d = [w_x, w_y, w_z, v_x, v_y, v_z] (body frame)
        w = twist_6d[:3] * dt  # angular displacement
        v = twist_6d[3:] * dt  # linear displacement
        
        # Skew-symmetric matrix for rotation
        w_skew = self._skew_symmetric(w)
        
        # Matrix exponential for rotation
        R_delta = torch.matrix_exp(w_skew)
        
        # ìƒˆë¡œìš´ pose ê³„ì‚°
        new_pose = pose.clone()
        new_pose[:3, :3] = pose[:3, :3] @ R_delta  # rotation ì—…ë°ì´íŠ¸
        new_pose[:3, 3] = pose[:3, 3] + pose[:3, :3] @ v  # position ì—…ë°ì´íŠ¸ (body frame)
        
        return new_pose
    
    def _skew_symmetric(self, w: torch.Tensor) -> torch.Tensor:
        """3D ë²¡í„°ë¥¼ skew-symmetric matrixë¡œ ë³€í™˜"""
        return torch.tensor([
            [0, -w[2], w[1]],
            [w[2], 0, -w[0]],
            [-w[1], w[0], 0]
        ], device=w.device, dtype=w.dtype)
    
    def _calculate_final_error(self, current: torch.Tensor, target: torch.Tensor) -> Dict:
        """ìµœì¢… ì˜¤ì°¨ ê³„ì‚°"""
        pos_error = torch.norm(current[:3, 3] - target[:3, 3])
        rot_error = self._rotation_angle_between(current[:3, :3], target[:3, :3])
        
        return {
            'position_error_m': pos_error.item(),
            'rotation_error_rad': rot_error.item(),
            'rotation_error_deg': torch.rad2deg(rot_error).item(),
            'total_distance': self._pose_distance(current, target).item(),
        }
    
    def _to_tensor(self, data: Union[torch.Tensor, np.ndarray]) -> torch.Tensor:
        """numpy arrayë¥¼ torch tensorë¡œ ë³€í™˜"""
        if isinstance(data, np.ndarray):
            data = torch.from_numpy(data).float()
        return data.to(self.device)
    
    def generate_multiple_trajectories(self, 
                                     starts: List[Union[torch.Tensor, np.ndarray]],
                                     targets: List[Union[torch.Tensor, np.ndarray]],
                                     pointclouds: List[Union[torch.Tensor, np.ndarray]],
                                     config: Optional[Dict] = None) -> List[Dict]:
        """ì—¬ëŸ¬ ê¶¤ì ì„ ë°°ì¹˜ë¡œ ìƒì„±"""
        results = []
        for start, target, pc in zip(starts, targets, pointclouds):
            result = self.generate_trajectory(start, target, pc, config)
            results.append(result)
        return results


# ì„¤ì • í”„ë¦¬ì…‹ë“¤
class InferenceConfigs:
    """ì¶”ë¡  ì„¤ì • í”„ë¦¬ì…‹"""
    
    @staticmethod
    def default():
        """ê¸°ë³¸ ì„¤ì • (ê· í˜•í˜•)"""
        return {
            'dt': 0.02,
            'max_steps': 100,
            'pos_tolerance': 0.02,
            'rot_tolerance': 0.1,
            'early_stop': True,
            'safety_check': True,
            'max_divergence': 2.0,
        }
    
    @staticmethod
    def high_quality():
        """ê³ í’ˆì§ˆ ì„¤ì • (ì •ë°€í˜•)"""
        return {
            'dt': 0.005,
            'max_steps': 400,
            'pos_tolerance': 0.005,
            'rot_tolerance': 0.05,
            'early_stop': True,
            'safety_check': True,
            'max_divergence': 2.0,
        }
    
    @staticmethod
    def fast():
        """ê³ ì† ìƒì„± ì„¤ì • (íš¨ìœ¨í˜•)"""
        return {
            'dt': 0.05,
            'max_steps': 50,
            'pos_tolerance': 0.05,
            'rot_tolerance': 0.2,
            'early_stop': True,
            'safety_check': False,
            'max_divergence': 3.0,
        }


def load_inference_engine(checkpoint_path: str, config_path: str = None, 
                         device: str = 'cuda') -> MotionRFMInference:
    """ì¶”ë¡  ì—”ì§„ ë¡œë“œ í—¬í¼ í•¨ìˆ˜"""
    if config_path is None:
        config_path = Path(checkpoint_path).parent / 'motion_rcfm.yml'
    
    return MotionRFMInference(checkpoint_path, config_path, device)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì˜ˆì‹œ ì‚¬ìš©ë²•
    print("ğŸš€ Motion RFM Inference Example")
    
    # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
    engine = MotionRFMInference(
        model_path="checkpoints/best_model.pth",
        config_path="configs/motion_rcfm.yml"
    )
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    start_pose = torch.eye(4)
    target_pose = torch.eye(4)
    target_pose[:3, 3] = torch.tensor([1.0, 1.0, 0.0])  # 1m, 1m ì´ë™
    pointcloud = torch.randn(1000, 3)  # ëœë¤ í¬ì¸íŠ¸í´ë¼ìš°ë“œ
    
    # ê¶¤ì  ìƒì„±
    result = engine.generate_trajectory(
        start_pose=start_pose,
        target_pose=target_pose,
        pointcloud=pointcloud,
        config=InferenceConfigs.default()
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"âœ… Success: {result['success']}")
    print(f"ğŸ“Š Steps: {result['steps']}")
    print(f"â±ï¸ Time: {result['generation_time']:.3f}s")
    print(f"ğŸ“ Final position error: {result['final_error']['position_error_m']:.3f}m")
    print(f"ğŸ”„ Final rotation error: {result['final_error']['rotation_error_deg']:.1f}Â°")


