#!/usr/bin/env python3
"""
ì •ê·œí™”ëœ Motion RFM ì¶”ë¡  ì—”ì§„
ì™„ì „í•œ ì •ê·œí™” ì–‘ë°©í–¥ íŒŒì´í”„ë¼ì¸ ì ìš©
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path
import time

from models import get_model
from utils.Lie import *
from omegaconf import OmegaConf
from utils.normalization import TwistNormalizer

class NormalizedMotionRFMInference:
    """ì •ê·œí™”ëœ Motion RFM ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self, model_path: str, config_path: str, 
                 normalize_twist: bool = True,
                 normalization_stats_path: str = "configs/normalization_stats.json"):
        """ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ì„¤ì • ë¡œë“œ
        self.config = OmegaConf.load(config_path)
        
        # ì •ê·œí™” ì„¤ì •
        self.normalize_twist = normalize_twist
        if normalize_twist:
            self.twist_normalizer = TwistNormalizer(stats_path=normalization_stats_path)
            print(f"âœ… Twist ì—­ì •ê·œí™” í™œì„±í™”: {normalization_stats_path}")
            print(self.twist_normalizer.get_stats_summary())
        else:
            self.twist_normalizer = None
            print("âš ï¸ Twist ì—­ì •ê·œí™” ë¹„í™œì„±í™”")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        self.model.eval()
        
        print(f"âœ… Normalized Motion RFM Inference Engine loaded on {self.device}")
        print(f"ğŸ“Š Model config: {self.config.model.arch}")
    
    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        model = get_model(self.config.model)
        
        if Path(model_path).exists():
            # PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ì‚¬ìš©
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            model.load_state_dict(checkpoint['model_state'])
            print(f"âœ… Model loaded from {model_path}")
        else:
            print(f"âš ï¸ Checkpoint not found: {model_path}, using random weights")
        
        return model.to(self.device)
    
    def generate_trajectory(self, 
                          start_pose: Union[torch.Tensor, np.ndarray],
                          target_pose: Union[torch.Tensor, np.ndarray], 
                          pointcloud: Union[torch.Tensor, np.ndarray],
                          config: Optional[Dict] = None) -> Dict:
        """ê¶¤ì  ìƒì„± (ì •ê·œí™” ì ìš©)"""
        
        # ê¸°ë³¸ ì„¤ì •
        cfg = {
            'dt': 0.05,                    # ì ë¶„ íƒ€ì„ìŠ¤í… (ê°œì„ ë¨)
            'max_steps': 200,              # ìµœëŒ€ ë°˜ë³µ ìˆ˜
            'pos_tolerance': 0.05,         # ìœ„ì¹˜ í—ˆìš© ì˜¤ì°¨ (m)
            'rot_tolerance': 0.1,          # íšŒì „ í—ˆìš© ì˜¤ì°¨ (rad)
            'early_stop': True,            # ì¡°ê¸° ì¢…ë£Œ ì‚¬ìš©
            'safety_check': True,          # ì•ˆì „ ì²´í¬ ì‚¬ìš©
            'safety_distance_threshold': 10.0,  # ì•ˆì „ ê±°ë¦¬ ì„ê³„ê°’
        }
        
        if config:
            cfg.update(config)
        
        # ì…ë ¥ í…ì„œ ë³€í™˜ ë° ë””ë°”ì´ìŠ¤ ì´ë™
        if isinstance(start_pose, np.ndarray):
            start_pose = torch.tensor(start_pose, dtype=torch.float32).to(self.device)
        else:
            start_pose = start_pose.to(self.device)
            
        if isinstance(target_pose, np.ndarray):
            target_pose = torch.tensor(target_pose, dtype=torch.float32).to(self.device)
        else:
            target_pose = target_pose.to(self.device)
            
        if isinstance(pointcloud, np.ndarray):
            pointcloud = torch.tensor(pointcloud, dtype=torch.float32).to(self.device)
        else:
            pointcloud = pointcloud.to(self.device)
        
        # ì´ˆê¸°í™”
        current_pose = start_pose.clone()
        trajectory = [current_pose.clone().cpu()]
        step = 0
        initial_distance = self._pose_distance(start_pose, target_pose).item()
        start_time = time.time()
        
        print(f"ğŸš€ ê¶¤ì  ìƒì„± ì‹œì‘ (ì •ê·œí™” ëª¨ë“œ: {'ON' if self.normalize_twist else 'OFF'})")
        print(f"   ì‹œì‘ â†’ ëª©í‘œ ê±°ë¦¬: {initial_distance:.3f}m")
        print(f"   ì„¤ì •: dt={cfg['dt']}, max_steps={cfg['max_steps']}")
        
        with torch.no_grad():
            while step < cfg['max_steps']:
                # 1. Progress ê³„ì‚°
                progress = self._calculate_progress(current_pose, start_pose, target_pose)
                
                # 2. ëª¨ë¸ ì¶”ë¡ : 6D twist vector ì˜ˆì¸¡ (ì •ê·œí™” ì ìš©)
                twist_6d = self._predict_twist(current_pose, target_pose, progress, pointcloud)
                
                # 3. ëª©í‘œ ë„ë‹¬ í™•ì¸ (ì¡°ê¸° ì¢…ë£Œ)
                if cfg['early_stop'] and self._reached_target(current_pose, target_pose, cfg):
                    print(f"âœ… ëª©í‘œ ë„ë‹¬! (ìŠ¤í…: {step})")
                    break
                
                # 4. ì•ˆì „ ì²´í¬
                if cfg['safety_check'] and self._safety_check(current_pose, target_pose, 
                                                            initial_distance, cfg):
                    print(f"âš ï¸ Safety check failed at step {step}")
                    break
                
                # 5. SE(3) ì ë¶„: twist â†’ next pose
                current_pose = self._integrate_se3(current_pose, twist_6d, cfg['dt'])
                
                # 6. ê¶¤ì ì— ì¶”ê°€
                trajectory.append(current_pose.clone().cpu())
                step += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if step % 50 == 0:
                    current_dist = self._pose_distance(current_pose, target_pose).item()
                    twist_norm = torch.norm(twist_6d).item()
                    print(f"   ìŠ¤í… {step}: ê±°ë¦¬ {current_dist:.3f}m, twistí¬ê¸° {twist_norm:.4f}")
        
        generation_time = time.time() - start_time
        final_error = self._compute_final_error(current_pose, target_pose)
        success = self._reached_target(current_pose, target_pose, cfg)
        
        result = {
            'trajectory': trajectory,
            'steps': step,
            'success': success,
            'generation_time': generation_time,
            'final_error': final_error,
            'config_used': cfg,
            'normalization_used': self.normalize_twist,
            'stats': {
                'initial_distance': initial_distance,
                'final_distance': self._pose_distance(current_pose, target_pose).item(),
                'avg_step_time': generation_time / max(step, 1),
            }
        }
        
        print(f"ğŸ¯ ìƒì„± ì™„ë£Œ: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}, {step}ìŠ¤í…, {generation_time:.3f}ì´ˆ")
        return result
    
    def _predict_twist(self, current_pose: torch.Tensor, target_pose: torch.Tensor,
                      progress: torch.Tensor, pointcloud: torch.Tensor) -> torch.Tensor:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 6D twist vector ì˜ˆì¸¡ (ì •ê·œí™” ì ìš©)"""
        # ì…ë ¥ ì¤€ë¹„ (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
        current_T = current_pose.unsqueeze(0)  # (1, 4, 4)
        target_T = target_pose.unsqueeze(0)    # (1, 4, 4)
        time_t = progress.unsqueeze(0).unsqueeze(0)  # (1, 1)
        pc = pointcloud.unsqueeze(0)           # (1, N, 3)
        
        # í¬ì¸íŠ¸í´ë¼ìš°ë“œ íŠ¹ì§• ì¶”ì¶œ (DGCNN ì…ë ¥ í˜•ì‹: [B, 3, N])
        pc_dgcnn = pc.transpose(1, 2)  # (1, 3, N)
        v = self.model.latent_feature(pc_dgcnn)  # (1, latent_dim)
        
        # ëª¨ë¸ì˜ velocity field ì§ì ‘ í˜¸ì¶œ (ì •ê·œí™”ëœ ì¶œë ¥)
        normalized_twist = self.model.velocity_field(current_T, target_T, time_t, v)  # (1, 6)
        normalized_twist = normalized_twist.squeeze(0)  # (6,)
        
        # ì—­ì •ê·œí™” (ì •ê·œí™”ëœ ì¶œë ¥ â†’ ì‹¤ì œ twist)
        if self.twist_normalizer is not None:
            real_twist = self.twist_normalizer.denormalize_twist(normalized_twist)
            return real_twist
        else:
            return normalized_twist
    
    def _calculate_progress(self, current: torch.Tensor, start: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """ì§„í–‰ë„ ê³„ì‚° (ê±°ë¦¬ ê¸°ë°˜)"""
        total_distance = self._pose_distance(start, target)
        current_distance = self._pose_distance(current, target)
        
        if total_distance < 1e-6:
            return torch.tensor(1.0, device=self.device)
        
        progress = 1.0 - (current_distance / total_distance)
        return torch.clamp(progress, 0.0, 1.0)
    
    def _pose_distance(self, pose1: torch.Tensor, pose2: torch.Tensor) -> torch.Tensor:
        """ë‘ SE(3) pose ê°„ì˜ ê±°ë¦¬"""
        # ìœ„ì¹˜ ê±°ë¦¬
        pos_dist = torch.norm(pose1[:3, 3] - pose2[:3, 3])
        
        # íšŒì „ ê±°ë¦¬ (Frobenius norm of rotation difference)
        rot_diff = pose1[:3, :3] - pose2[:3, :3]
        rot_dist = torch.norm(rot_diff, 'fro')
        
        # ê°€ì¤‘ í•© (ìœ„ì¹˜ì™€ íšŒì „ ìŠ¤ì¼€ì¼ ì¡°ì •)
        return pos_dist + 0.1 * rot_dist
    
    def _reached_target(self, current: torch.Tensor, target: torch.Tensor, config: Dict) -> bool:
        """ëª©í‘œ ë„ë‹¬ ì—¬ë¶€ íŒë³„"""
        pos_error = torch.norm(current[:3, 3] - target[:3, 3])
        rot_error = self._rotation_angle_between(current[:3, :3], target[:3, :3])
        
        return (pos_error < config['pos_tolerance']) and (rot_error < config['rot_tolerance'])
    
    def _rotation_angle_between(self, R1: torch.Tensor, R2: torch.Tensor) -> torch.Tensor:
        """ë‘ íšŒì „ í–‰ë ¬ ê°„ì˜ ê°ë„ ì°¨ì´"""
        R_rel = R1.T @ R2
        trace = torch.trace(R_rel)
        cos_angle = (trace - 1) / 2
        cos_angle = torch.clamp(cos_angle, -1.0, 1.0)
        return torch.acos(cos_angle)
    
    def _safety_check(self, current: torch.Tensor, target: torch.Tensor, 
                     initial_distance: float, config: Dict) -> bool:
        """ì•ˆì „ ì²´í¬ (ë°œì‚° ë°©ì§€)"""
        current_distance = self._pose_distance(current, target).item()
        
        # ì´ˆê¸° ê±°ë¦¬ì˜ Në°° ì´ìƒ ë©€ì–´ì§€ë©´ ì‹¤íŒ¨
        if current_distance > config['safety_distance_threshold'] * initial_distance:
            return True
        
        return False
    
    def _integrate_se3(self, pose: torch.Tensor, twist: torch.Tensor, dt: float) -> torch.Tensor:
        """SE(3) ì ë¶„ (Euler method)"""
        # Twist vector: [Ï‰x, Ï‰y, Ï‰z, vx, vy, vz] (body frame)
        omega = twist[:3] * dt  # ê°ì†ë„ * dt
        v = twist[3:] * dt      # ì„ ì†ë„ * dt
        
        # Current pose
        R = pose[:3, :3]
        p = pose[:3, 3]
        
        # íšŒì „ ì—…ë°ì´íŠ¸ (rodrigues formula)
        omega_norm = torch.norm(omega)
        if omega_norm > 1e-6:
            omega_hat = omega / omega_norm
            omega_skew = torch.tensor([
                [0, -omega_hat[2], omega_hat[1]],
                [omega_hat[2], 0, -omega_hat[0]],
                [-omega_hat[1], omega_hat[0], 0]
            ], device=pose.device)
            
            R_new = R @ (torch.eye(3, device=pose.device) + 
                        torch.sin(omega_norm) * omega_skew + 
                        (1 - torch.cos(omega_norm)) * (omega_skew @ omega_skew))
        else:
            R_new = R
        
        # ìœ„ì¹˜ ì—…ë°ì´íŠ¸ (body frame velocityë¥¼ world frameìœ¼ë¡œ ë³€í™˜)
        p_new = p + R @ v
        
        # ìƒˆë¡œìš´ SE(3) pose
        new_pose = torch.eye(4, device=pose.device)
        new_pose[:3, :3] = R_new
        new_pose[:3, 3] = p_new
        
        return new_pose
    
    def _compute_final_error(self, current: torch.Tensor, target: torch.Tensor) -> Dict:
        """ìµœì¢… ì˜¤ì°¨ ê³„ì‚°"""
        pos_error = torch.norm(current[:3, 3] - target[:3, 3])
        rot_error = self._rotation_angle_between(current[:3, :3], target[:3, :3])
        
        return {
            'position_error_m': pos_error.item(),
            'rotation_error_rad': rot_error.item(),
            'rotation_error_deg': torch.rad2deg(rot_error).item(),
        }

# í¸ì˜ í•¨ìˆ˜ë“¤
class NormalizedInferenceConfigs:
    """ì •ê·œí™”ëœ ì¶”ë¡  ì„¤ì • í”„ë¦¬ì…‹"""
    
    @staticmethod
    def default():
        return {
            'dt': 0.05,
            'max_steps': 200,
            'pos_tolerance': 0.05,
            'rot_tolerance': 0.1,
            'early_stop': True,
            'safety_check': True,
            'safety_distance_threshold': 5.0,
        }
    
    @staticmethod
    def fast():
        return {
            'dt': 0.1,
            'max_steps': 100,
            'pos_tolerance': 0.1,
            'rot_tolerance': 0.2,
            'early_stop': True,
            'safety_check': True,
            'safety_distance_threshold': 3.0,
        }
    
    @staticmethod
    def precise():
        return {
            'dt': 0.02,
            'max_steps': 500,
            'pos_tolerance': 0.01,
            'rot_tolerance': 0.05,
            'early_stop': True,
            'safety_check': True,
            'safety_distance_threshold': 10.0,
        }

if __name__ == "__main__":
    print("ğŸ§ª ì •ê·œí™”ëœ ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    engine = NormalizedMotionRFMInference(
        'checkpoints/motion_rcfm_final_epoch10.pth',
        'configs/motion_rcfm.yml',
        normalize_twist=True
    )
    
    # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    start_pose = torch.eye(4, dtype=torch.float32)
    target_pose = torch.eye(4, dtype=torch.float32)
    target_pose[:3, 3] = torch.tensor([2.0, 2.0, 0.0])
    pointcloud = torch.randn(300, 3)
    
    result = engine.generate_trajectory(
        start_pose, target_pose, pointcloud, 
        NormalizedInferenceConfigs.default()
    )
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {result['steps']}ìŠ¤í…, {'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}")

