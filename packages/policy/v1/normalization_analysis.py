#!/usr/bin/env python3
"""
ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì™„ì „ ë¶„ì„
"""

import torch
import numpy as np
import json
import sys
import os
from pathlib import Path

sys.path.append('.')
from loaders.trajectory_dataset import TrajectoryDataset

def analyze_normalization_pipeline():
    """ì •ê·œí™”ê°€ í•„ìš”í•œ ëª¨ë“  ë‹¨ê³„ ë¶„ì„"""
    print("ğŸ” ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì™„ì „ ë¶„ì„")
    print("=" * 60)
    
    # 1. í•™ìŠµ ë°ì´í„°ì—ì„œ í†µê³„ ì¶”ì¶œ
    print("ğŸ“Š 1ë‹¨ê³„: í•™ìŠµ ë°ì´í„° í†µê³„ ì¶”ì¶œ")
    print("-" * 40)
    
    trajectory_root = "../../../data/trajectories/circle_envs_10k_bsplined"
    pointcloud_root = "../../../data/pointcloud/circle_envs_10k/circle_envs_10k"
    
    dataset = TrajectoryDataset(
        trajectory_root=trajectory_root,
        pointcloud_root=pointcloud_root,
        split='train',
        max_trajectories=100,  # í†µê³„ìš©ìœ¼ë¡œ ì¶©ë¶„
        use_bsplined=True,
        augment_data=False,
        num_points=300
    )
    
    # Twist vector í†µê³„ ìˆ˜ì§‘
    all_twists = []
    all_positions = []
    all_distances = []
    
    print(f"ğŸ“ˆ {len(dataset)} ìƒ˜í”Œì—ì„œ í†µê³„ ìˆ˜ì§‘ ì¤‘...")
    
    for i in range(min(len(dataset), 2000)):  # 2000ê°œ ìƒ˜í”Œ
        if i % 500 == 0:
            print(f"   ì§„í–‰ë¥ : {i}/{min(len(dataset), 2000)}")
        
        try:
            sample = dataset[i]
            T_dot = sample['T_dot'].numpy()
            current_T = sample['current_T'].numpy()
            target_T = sample['target_T'].numpy()
            
            all_twists.append(T_dot)
            all_positions.append(current_T[:3, 3])
            
            # í˜„ì¬-ëª©í‘œ ê±°ë¦¬
            distance = np.linalg.norm(target_T[:3, 3] - current_T[:3, 3])
            all_distances.append(distance)
            
        except Exception as e:
            continue
    
    all_twists = np.array(all_twists)  # [N, 6]
    all_positions = np.array(all_positions)  # [N, 3]
    all_distances = np.array(all_distances)  # [N]
    
    # í†µê³„ ê³„ì‚°
    twist_stats = {
        'angular': {
            'mean': np.mean(all_twists[:, :3], axis=0),
            'std': np.std(all_twists[:, :3], axis=0),
            'overall_mean': np.mean(np.linalg.norm(all_twists[:, :3], axis=1)),
            'overall_std': np.std(np.linalg.norm(all_twists[:, :3], axis=1))
        },
        'linear': {
            'mean': np.mean(all_twists[:, 3:], axis=0),
            'std': np.std(all_twists[:, 3:], axis=0),
            'overall_mean': np.mean(np.linalg.norm(all_twists[:, 3:], axis=1)),
            'overall_std': np.std(np.linalg.norm(all_twists[:, 3:], axis=1))
        },
        'total': {
            'mean': np.mean(all_twists, axis=0),
            'std': np.std(all_twists, axis=0),
            'overall_mean': np.mean(np.linalg.norm(all_twists, axis=1)),
            'overall_std': np.std(np.linalg.norm(all_twists, axis=1))
        }
    }
    
    position_stats = {
        'mean': np.mean(all_positions, axis=0),
        'std': np.std(all_positions, axis=0)
    }
    
    distance_stats = {
        'mean': np.mean(all_distances),
        'std': np.std(all_distances),
        'min': np.min(all_distances),
        'max': np.max(all_distances)
    }
    
    print(f"\nğŸ“Š ì¶”ì¶œëœ í†µê³„:")
    print(f"   Angular velocity:")
    print(f"      í‰ê·  í¬ê¸°: {twist_stats['angular']['overall_mean']:.4f} Â± {twist_stats['angular']['overall_std']:.4f} rad/s")
    print(f"      ì„±ë¶„ë³„ í‰ê· : {twist_stats['angular']['mean']}")
    print(f"      ì„±ë¶„ë³„ í‘œì¤€í¸ì°¨: {twist_stats['angular']['std']}")
    
    print(f"   Linear velocity:")
    print(f"      í‰ê·  í¬ê¸°: {twist_stats['linear']['overall_mean']:.4f} Â± {twist_stats['linear']['overall_std']:.4f} m/s")
    print(f"      ì„±ë¶„ë³„ í‰ê· : {twist_stats['linear']['mean']}")
    print(f"      ì„±ë¶„ë³„ í‘œì¤€í¸ì°¨: {twist_stats['linear']['std']}")
    
    print(f"   Position:")
    print(f"      í‰ê· : {position_stats['mean']}")
    print(f"      í‘œì¤€í¸ì°¨: {position_stats['std']}")
    
    print(f"   Distance to target:")
    print(f"      í‰ê· : {distance_stats['mean']:.4f} Â± {distance_stats['std']:.4f} m")
    print(f"      ë²”ìœ„: [{distance_stats['min']:.4f}, {distance_stats['max']:.4f}] m")
    
    return twist_stats, position_stats, distance_stats

def create_normalization_configs(twist_stats, position_stats, distance_stats):
    """ì •ê·œí™” ì„¤ì • íŒŒì¼ ìƒì„±"""
    print("\nğŸ“ 2ë‹¨ê³„: ì •ê·œí™” ì„¤ì • íŒŒì¼ ìƒì„±")
    print("-" * 40)
    
    # ì •ê·œí™” ì„¤ì •
    norm_config = {
        'twist_normalization': {
            'method': 'standardization',  # (x - mean) / std
            'angular': {
                'mean': twist_stats['angular']['mean'].tolist(),
                'std': twist_stats['angular']['std'].tolist(),
                'overall_mean': float(twist_stats['angular']['overall_mean']),
                'overall_std': float(twist_stats['angular']['overall_std'])
            },
            'linear': {
                'mean': twist_stats['linear']['mean'].tolist(),
                'std': twist_stats['linear']['std'].tolist(),
                'overall_mean': float(twist_stats['linear']['overall_mean']),
                'overall_std': float(twist_stats['linear']['overall_std'])
            },
            'total': {
                'mean': twist_stats['total']['mean'].tolist(),
                'std': twist_stats['total']['std'].tolist(),
                'overall_mean': float(twist_stats['total']['overall_mean']),
                'overall_std': float(twist_stats['total']['overall_std'])
            }
        },
        'position_normalization': {
            'method': 'standardization',
            'mean': position_stats['mean'].tolist(),
            'std': position_stats['std'].tolist()
        },
        'distance_normalization': {
            'method': 'standardization',
            'mean': float(distance_stats['mean']),
            'std': float(distance_stats['std']),
            'min': float(distance_stats['min']),
            'max': float(distance_stats['max'])
        }
    }
    
    # ì €ì¥
    config_path = "configs/normalization_stats.json"
    with open(config_path, 'w') as f:
        json.dump(norm_config, f, indent=2)
    
    print(f"âœ… ì •ê·œí™” ì„¤ì • ì €ì¥: {config_path}")
    
    return norm_config

def demonstrate_normalization_pipeline(norm_config):
    """ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì‹œì—°"""
    print("\nğŸ”„ 3ë‹¨ê³„: ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì‹œì—°")
    print("-" * 40)
    
    # ì›ë³¸ ë°ì´í„° (ì˜ˆì‹œ)
    original_twist = np.array([0.5, -0.2, 0.1, 3.2, 1.8, -0.5])  # [wx, wy, wz, vx, vy, vz]
    
    print(f"ğŸ“¥ ì›ë³¸ twist: {original_twist}")
    
    # 1. í•™ìŠµ ì‹œ ì •ê·œí™” (ë°ì´í„°ì…‹ì—ì„œ)
    twist_mean = np.array(norm_config['twist_normalization']['total']['mean'])
    twist_std = np.array(norm_config['twist_normalization']['total']['std'])
    
    normalized_twist = (original_twist - twist_mean) / twist_std
    print(f"ğŸ“¤ ì •ê·œí™”ëœ twist: {normalized_twist}")
    print(f"   í¬ê¸°: {np.linalg.norm(normalized_twist):.4f} (ì›ë³¸: {np.linalg.norm(original_twist):.4f})")
    
    # 2. ì¶”ë¡  ì‹œ ì—­ì •ê·œí™” (ëª¨ë¸ ì¶œë ¥ â†’ ì‹¤ì œ twist)
    model_output = normalized_twist * 0.1  # ëª¨ë¸ì´ ì‘ê²Œ ì˜ˆì¸¡í•œë‹¤ê³  ê°€ì •
    denormalized_twist = model_output * twist_std + twist_mean
    
    print(f"ğŸ¤– ëª¨ë¸ ì¶œë ¥ (ì •ê·œí™”ë¨): {model_output}")
    print(f"ğŸ”„ ì—­ì •ê·œí™”ëœ twist: {denormalized_twist}")
    print(f"   í¬ê¸°: {np.linalg.norm(denormalized_twist):.4f}")
    
    return norm_config

def analyze_what_needs_normalization():
    """ì–´ë–¤ ë¶€ë¶„ì— ì •ê·œí™”ê°€ í•„ìš”í•œì§€ ë¶„ì„"""
    print("\nğŸ¯ 4ë‹¨ê³„: ì •ê·œí™” í•„ìš” ë¶€ë¶„ ë¶„ì„")
    print("-" * 40)
    
    print("ğŸ“‹ ì •ê·œí™”ê°€ í•„ìš”í•œ ë‹¨ê³„ë“¤:")
    print()
    
    print("1ï¸âƒ£ **í•™ìŠµ ë°ì´í„° (Dataset)**")
    print("   ğŸ“ ìœ„ì¹˜: trajectory_dataset.py")
    print("   ğŸ”„ ì •ê·œí™”: T_dot (twist vector)")
    print("   ğŸ“Š ë°©ë²•: (T_dot - mean) / std")
    print("   âš ï¸ ì£¼ì˜: í†µê³„ëŠ” ì „ì²´ í•™ìŠµì…‹ì—ì„œ ë¯¸ë¦¬ ê³„ì‚°")
    print()
    
    print("2ï¸âƒ£ **ëª¨ë¸ ì¶œë ¥ (Loss ê³„ì‚°)**")
    print("   ğŸ“ ìœ„ì¹˜: train.py ë˜ëŠ” trainer")
    print("   ğŸ”„ ì •ê·œí™”: ì´ë¯¸ ì •ê·œí™”ëœ ìƒíƒœë¡œ loss ê³„ì‚°")
    print("   ğŸ“Š ë°©ë²•: MSE(predicted_normalized, target_normalized)")
    print()
    
    print("3ï¸âƒ£ **ì¶”ë¡  ì‹œ ì—­ì •ê·œí™” (Inference)**")
    print("   ğŸ“ ìœ„ì¹˜: inference.py")
    print("   ğŸ”„ ì—­ì •ê·œí™”: model_output â†’ ì‹¤ì œ twist")
    print("   ğŸ“Š ë°©ë²•: real_twist = normalized_output * std + mean")
    print("   âš ï¸ ì¤‘ìš”: ì´ ë‹¨ê³„ê°€ ì—†ìœ¼ë©´ ëª¨ë¸ ì¶œë ¥ì´ ì‘ê²Œ ë‚˜ì˜´!")
    print()
    
    print("4ï¸âƒ£ **ì„¤ì • íŒŒì¼ (Config)**")
    print("   ğŸ“ ìœ„ì¹˜: configs/normalization_stats.json")
    print("   ğŸ”„ ì €ì¥: í•™ìŠµ ë°ì´í„°ì—ì„œ ê³„ì‚°ëœ í†µê³„")
    print("   ğŸ“Š ë‚´ìš©: mean, std for angular/linear velocity")
    print()
    
    print("âŒ **í˜„ì¬ ìƒí™© ë¶„ì„:**")
    print("   1ë‹¨ê³„: âŒ Datasetì—ì„œ ì •ê·œí™” ì•ˆí•¨")
    print("   2ë‹¨ê³„: âŒ Loss ê³„ì‚° ì‹œ ì •ê·œí™” ì•ˆí•¨")
    print("   3ë‹¨ê³„: âŒ Inferenceì—ì„œ ì—­ì •ê·œí™” ì•ˆí•¨")
    print("   4ë‹¨ê³„: âŒ ì •ê·œí™” í†µê³„ ì—†ìŒ")
    print()
    
    print("âœ… **í•´ê²° ë°©ë²•:**")
    print("   â†’ 4ë‹¨ê³„ ëª¨ë‘ êµ¬í˜„ í•„ìš”!")
    print("   â†’ ë‹¨ìˆœíˆ í•™ìŠµ ë°ì´í„°ë§Œ ì •ê·œí™”í•˜ë©´ ì¶”ë¡  ì‹œ ë¬¸ì œ ë°œìƒ")
    print("   â†’ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì¼ê´€ë˜ê²Œ ì •ê·œí™”í•´ì•¼ í•¨")

def create_implementation_plan():
    """êµ¬í˜„ ê³„íš ì œì‹œ"""
    print("\nğŸš€ 5ë‹¨ê³„: êµ¬í˜„ ê³„íš")
    print("-" * 40)
    
    print("ğŸ“‹ **ì¦‰ì‹œ êµ¬í˜„ ê³„íš (ìš°ì„ ìˆœìœ„ ìˆœ):**")
    print()
    
    print("ğŸ¥‡ **1ìˆœìœ„: ì¶”ë¡  ì‹œ ìŠ¤ì¼€ì¼ë§ (ì„ì‹œ í•´ê²°)**")
    print("   ğŸ“ íŒŒì¼: inference.py")
    print("   ğŸ”§ ë°©ë²•: velocity_scale=50 ì ìš©")
    print("   â±ï¸ ì‹œê°„: 10ë¶„")
    print("   ğŸ’¡ íš¨ê³¼: ì¦‰ì‹œ 100ë°° ê°œì„ ")
    print()
    
    print("ğŸ¥ˆ **2ìˆœìœ„: ì •ê·œí™” í†µê³„ ìƒì„±**")
    print("   ğŸ“ íŒŒì¼: configs/normalization_stats.json")
    print("   ğŸ”§ ë°©ë²•: ìœ„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
    print("   â±ï¸ ì‹œê°„: 5ë¶„")
    print("   ğŸ’¡ íš¨ê³¼: ì •í™•í•œ í†µê³„ í™•ë³´")
    print()
    
    print("ğŸ¥‰ **3ìˆœìœ„: Dataset ì •ê·œí™” êµ¬í˜„**")
    print("   ğŸ“ íŒŒì¼: loaders/trajectory_dataset.py")
    print("   ğŸ”§ ë°©ë²•: __getitem__ì—ì„œ T_dot ì •ê·œí™”")
    print("   â±ï¸ ì‹œê°„: 30ë¶„")
    print("   ğŸ’¡ íš¨ê³¼: í•™ìŠµ ë°ì´í„° ì •ê·œí™”")
    print()
    
    print("ğŸ… **4ìˆœìœ„: Inference ì—­ì •ê·œí™” êµ¬í˜„**")
    print("   ğŸ“ íŒŒì¼: inference.py")
    print("   ğŸ”§ ë°©ë²•: _predict_twistì—ì„œ ì—­ì •ê·œí™”")
    print("   â±ï¸ ì‹œê°„: 20ë¶„")
    print("   ğŸ’¡ íš¨ê³¼: ì •í™•í•œ ìŠ¤ì¼€ì¼ ë³µì›")
    print()
    
    print("ğŸ¯ **ì¬í•™ìŠµ (ì¥ê¸°)**")
    print("   ğŸ“ ê³¼ì •: ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ì „ì²´ ì¬í•™ìŠµ")
    print("   â±ï¸ ì‹œê°„: 2-3ì‹œê°„")
    print("   ğŸ’¡ íš¨ê³¼: ê·¼ë³¸ì  í•´ê²°")
    print()
    
    print("ğŸ’¡ **ì¶”ì²œ ì ‘ê·¼ë²•:**")
    print("   1. ë¨¼ì € 1ìˆœìœ„(ì„ì‹œ ìŠ¤ì¼€ì¼ë§)ë¡œ ì¦‰ì‹œ ê°œì„ ")
    print("   2. ê·¸ ë‹¤ìŒ 2-4ìˆœìœ„ êµ¬í˜„í•˜ì—¬ ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì™„ì„±")
    print("   3. ë§ˆì§€ë§‰ì— ì¬í•™ìŠµìœ¼ë¡œ ê·¼ë³¸ í•´ê²°")

if __name__ == "__main__":
    print("ğŸš€ ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì™„ì „ ë¶„ì„ ì‹œì‘")
    print()
    
    # 1. í•™ìŠµ ë°ì´í„° í†µê³„ ë¶„ì„
    twist_stats, position_stats, distance_stats = analyze_normalization_pipeline()
    
    # 2. ì •ê·œí™” ì„¤ì • ìƒì„±
    norm_config = create_normalization_configs(twist_stats, position_stats, distance_stats)
    
    # 3. ì •ê·œí™” íŒŒì´í”„ë¼ì¸ ì‹œì—°
    demonstrate_normalization_pipeline(norm_config)
    
    # 4. í•„ìš”í•œ ì •ê·œí™” ë‹¨ê³„ ë¶„ì„
    analyze_what_needs_normalization()
    
    # 5. êµ¬í˜„ ê³„íš
    create_implementation_plan()
    
    print("\n" + "="*60)
    print("ğŸ¯ ê²°ë¡ ")
    print("="*60)
    print("âŒ í•™ìŠµ ë°ì´í„° ì •ê·œí™”ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•¨!")
    print("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ â†’ ì¶”ë¡ ) ì •ê·œí™” í•„ìš”")
    print("ğŸš€ ìš°ì„  ì„ì‹œ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¦‰ì‹œ ê°œì„  í›„")
    print("ğŸ”§ ì™„ì „í•œ ì •ê·œí™” íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ê¶Œì¥")
    print()
    print("âœ… ë¶„ì„ ì™„ë£Œ!")

