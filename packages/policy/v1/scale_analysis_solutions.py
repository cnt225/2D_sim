#!/usr/bin/env python3
"""
ëª¨ë¸ ì¶œë ¥ ìŠ¤ì¼€ì¼ ë¬¸ì œ í•´ê²°ì±…ë“¤
"""

import torch
import numpy as np
import json
import sys
import os

sys.path.append('.')
from inference import MotionRFMInference, InferenceConfigs

def solution_1_scale_dt():
    """í•´ê²°ì±… 1: dt í¬ê¸° ì¡°ì •ìœ¼ë¡œ ì¦‰ì‹œ ê°œì„ """
    print("ğŸ”§ í•´ê²°ì±… 1: dt ìŠ¤ì¼€ì¼ ì¡°ì •")
    print("=" * 50)
    
    engine = MotionRFMInference('checkpoints/motion_rcfm_final_epoch10.pth', 'configs/motion_rcfm.yml')
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    device = engine.device
    start = torch.eye(4, dtype=torch.float32, device=device)
    target = torch.eye(4, dtype=torch.float32, device=device)
    target[:3, 3] = torch.tensor([2.0, 2.0, 0.0], device=device)
    pc = torch.randn(300, 3, device=device)
    
    # í˜„ì¬ ì„¤ì • vs ê°œì„ ëœ ì„¤ì •
    configs = {
        "í˜„ì¬": {"dt": 0.02, "max_steps": 500},
        "ê°œì„  1ë‹¨ê³„": {"dt": 0.1, "max_steps": 200},  # 5ë°° ì¦ê°€
        "ê°œì„  2ë‹¨ê³„": {"dt": 0.2, "max_steps": 100},  # 10ë°° ì¦ê°€
        "ì ê·¹ì ": {"dt": 0.5, "max_steps": 50}      # 25ë°° ì¦ê°€
    }
    
    results = {}
    
    for name, config in configs.items():
        print(f"\nğŸ“Š {name} ì„¤ì • í…ŒìŠ¤íŠ¸:")
        print(f"   dt: {config['dt']}, max_steps: {config['max_steps']}")
        
        result = engine.generate_trajectory(start, target, pc, config)
        
        # ê¶¤ì  ë¶„ì„
        trajectory = result['trajectory']
        total_distance = 0
        for i in range(1, len(trajectory)):
            dist = torch.norm(trajectory[i][:3, 3] - trajectory[i-1][:3, 3]).item()
            total_distance += dist
        
        avg_step_size = total_distance / max(1, len(trajectory) - 1)
        
        print(f"   ìŠ¤í… ìˆ˜: {result['steps']}")
        print(f"   ì´ ì´ë™: {total_distance:.4f}m")
        print(f"   í‰ê·  ìŠ¤í…: {avg_step_size*1000:.1f}mm")
        print(f"   ì‹œê°„: {result['generation_time']:.3f}ì´ˆ")
        print(f"   ì„±ê³µ: {result['success']}")
        
        results[name] = {
            'dt': config['dt'],
            'steps': result['steps'],
            'total_distance': total_distance,
            'avg_step_size_mm': avg_step_size * 1000,
            'time': result['generation_time'],
            'success': result['success']
        }
    
    print(f"\nğŸ“ˆ ê²°ê³¼ ìš”ì•½:")
    for name, res in results.items():
        print(f"   {name:12s}: {res['avg_step_size_mm']:6.1f}mm/step, "
              f"{res['total_distance']:6.3f}m ì´ë™, {res['time']:5.2f}ì´ˆ")
    
    return results

def solution_2_velocity_scaling():
    """í•´ê²°ì±… 2: ì¶”ë¡  ì‹œ velocity ìŠ¤ì¼€ì¼ë§"""
    print("\nğŸ”§ í•´ê²°ì±… 2: Velocity ìŠ¤ì¼€ì¼ë§")
    print("=" * 50)
    
    # ê°œì„ ëœ ì¶”ë¡  ì—”ì§„ (velocity scaling í¬í•¨)
    class ScaledMotionRFMInference(MotionRFMInference):
        def __init__(self, *args, velocity_scale=1.0, **kwargs):
            super().__init__(*args, **kwargs)
            self.velocity_scale = velocity_scale
            print(f"âœ… Velocity ìŠ¤ì¼€ì¼ íŒ©í„°: {velocity_scale}")
        
        def _predict_twist(self, current_pose, target_pose, progress, pointcloud):
            # ì›ë³¸ twist ì˜ˆì¸¡
            twist = super()._predict_twist(current_pose, target_pose, progress, pointcloud)
            
            # ìŠ¤ì¼€ì¼ë§ ì ìš©
            scaled_twist = twist * self.velocity_scale
            
            return scaled_twist
    
    # ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ íŒ©í„° í…ŒìŠ¤íŠ¸
    scale_factors = [1.0, 10.0, 50.0, 100.0]
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    start = torch.eye(4, dtype=torch.float32, device=device)
    target = torch.eye(4, dtype=torch.float32, device=device)
    target[:3, 3] = torch.tensor([2.0, 2.0, 0.0], device=device)
    pc = torch.randn(300, 3, device=device)
    
    results = {}
    
    for scale in scale_factors:
        print(f"\nğŸ“Š ìŠ¤ì¼€ì¼ íŒ©í„° {scale:.1f} í…ŒìŠ¤íŠ¸:")
        
        engine = ScaledMotionRFMInference(
            'checkpoints/motion_rcfm_final_epoch10.pth', 
            'configs/motion_rcfm.yml',
            velocity_scale=scale
        )
        
        config = {"dt": 0.05, "max_steps": 200}  # ì ë‹¹í•œ ì„¤ì •
        result = engine.generate_trajectory(start, target, pc, config)
        
        # ê¶¤ì  ë¶„ì„
        trajectory = result['trajectory']
        total_distance = 0
        for i in range(1, len(trajectory)):
            dist = torch.norm(trajectory[i][:3, 3] - trajectory[i-1][:3, 3]).item()
            total_distance += dist
        
        avg_step_size = total_distance / max(1, len(trajectory) - 1)
        
        print(f"   ìŠ¤í… ìˆ˜: {result['steps']}")
        print(f"   ì´ ì´ë™: {total_distance:.4f}m")
        print(f"   í‰ê·  ìŠ¤í…: {avg_step_size*1000:.1f}mm")
        print(f"   ì„±ê³µ: {result['success']}")
        
        results[f"scale_{scale}"] = {
            'scale': scale,
            'steps': result['steps'],
            'total_distance': total_distance,
            'avg_step_size_mm': avg_step_size * 1000,
            'success': result['success']
        }
    
    return results

def solution_3_adaptive_inference():
    """í•´ê²°ì±… 3: ì ì‘ì  ì¶”ë¡  (ê±°ë¦¬ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§)"""
    print("\nğŸ”§ í•´ê²°ì±… 3: ì ì‘ì  ì¶”ë¡ ")
    print("=" * 50)
    
    class AdaptiveMotionRFMInference(MotionRFMInference):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
        
        def _predict_twist(self, current_pose, target_pose, progress, pointcloud):
            # ì›ë³¸ twist ì˜ˆì¸¡
            twist = super()._predict_twist(current_pose, target_pose, progress, pointcloud)
            
            # ê±°ë¦¬ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
            distance = torch.norm(target_pose[:3, 3] - current_pose[:3, 3])
            
            # ê±°ë¦¬ê°€ í´ìˆ˜ë¡ ë” í° ì†ë„ (í•˜ì§€ë§Œ ì œí•œ)
            distance_scale = torch.clamp(distance * 10.0, min=1.0, max=100.0)
            
            # Progress ê¸°ë°˜ ì¡°ì • (ì‹œì‘í•  ë•Œ ë” ë¹ ë¥´ê²Œ)
            progress_scale = torch.clamp(2.0 - progress, min=0.5, max=2.0)
            
            total_scale = distance_scale * progress_scale
            scaled_twist = twist * total_scale
            
            return scaled_twist
    
    print("ğŸ“Š ì ì‘ì  ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
    
    engine = AdaptiveMotionRFMInference(
        'checkpoints/motion_rcfm_final_epoch10.pth', 
        'configs/motion_rcfm.yml'
    )
    
    device = engine.device
    start = torch.eye(4, dtype=torch.float32, device=device)
    target = torch.eye(4, dtype=torch.float32, device=device)
    target[:3, 3] = torch.tensor([3.0, 3.0, 0.0], device=device)  # ë” ë¨¼ ê±°ë¦¬
    pc = torch.randn(300, 3, device=device)
    
    config = {"dt": 0.05, "max_steps": 200}
    result = engine.generate_trajectory(start, target, pc, config)
    
    # ê¶¤ì  ë¶„ì„
    trajectory = result['trajectory']
    total_distance = 0
    step_sizes = []
    for i in range(1, len(trajectory)):
        dist = torch.norm(trajectory[i][:3, 3] - trajectory[i-1][:3, 3]).item()
        total_distance += dist
        step_sizes.append(dist)
    
    print(f"   ìŠ¤í… ìˆ˜: {result['steps']}")
    print(f"   ì´ ì´ë™: {total_distance:.4f}m")
    print(f"   í‰ê·  ìŠ¤í…: {np.mean(step_sizes)*1000:.1f}mm")
    print(f"   ìµœëŒ€ ìŠ¤í…: {np.max(step_sizes)*1000:.1f}mm")
    print(f"   ìµœì†Œ ìŠ¤í…: {np.min(step_sizes)*1000:.1f}mm")
    print(f"   ì„±ê³µ: {result['success']}")
    
    return {
        'total_distance': total_distance,
        'avg_step_size_mm': np.mean(step_sizes) * 1000,
        'step_variation': np.std(step_sizes) * 1000
    }

def recommend_best_solution():
    """ìµœì  í•´ê²°ì±… ì¶”ì²œ"""
    print("\n" + "="*60)
    print("ğŸ¯ ìµœì  í•´ê²°ì±… ì¶”ì²œ")
    print("="*60)
    
    print("ğŸ“‹ ë‹¨ê¸° í•´ê²°ì±… (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥):")
    print("   1. dt ì¡°ì •: 0.02 â†’ 0.1 (5ë°° ì¦ê°€)")
    print("      âœ… ì½”ë“œ ìˆ˜ì • ì—†ìŒ")
    print("      âœ… ì¦‰ì‹œ íš¨ê³¼")
    print("      âŒ ê¶¤ì  í’ˆì§ˆ ì•½ê°„ ì €í•˜")
    print()
    
    print("   2. Velocity ìŠ¤ì¼€ì¼ë§: 50-100ë°°")
    print("      âœ… í•™ìŠµ ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë§ì¶¤")
    print("      âœ… ê¶¤ì  í’ˆì§ˆ ìœ ì§€")
    print("      âŒ ì¶”ë¡  ì½”ë“œ ìˆ˜ì • í•„ìš”")
    print()
    
    print("ğŸ“‹ ì¤‘ê¸° í•´ê²°ì±… (ëª¨ë¸ ê°œì„ ):")
    print("   1. Loss ì •ê·œí™” ì¶”ê°€")
    print("      - Twist vectorë¥¼ í•™ìŠµ ë°ì´í„° í‰ê· ìœ¼ë¡œ ì •ê·œí™”")
    print("      - MSE Loss ì „ì— ìŠ¤ì¼€ì¼ ì¡°ì •")
    print()
    
    print("   2. ë” ë‚˜ì€ Loss í•¨ìˆ˜")
    print("      - Weighted MSE (linear vs angular)")
    print("      - Progress-aware loss")
    print("      - Distance-aware loss")
    print()
    
    print("ğŸ“‹ ì¥ê¸° í•´ê²°ì±… (ì¬í•™ìŠµ):")
    print("   1. ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ì¬í•™ìŠµ")
    print("   2. ë” í° ëª¨ë¸ (velocity field ë„¤íŠ¸ì›Œí¬ í™•ì¥)")
    print("   3. ë‹¤ë¥¸ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„")
    print()
    
    print("ğŸš€ ê¶Œì¥ ì¦‰ì‹œ ì ìš©:")
    print("   InferenceConfigsì— velocity_scale=50.0 ì¶”ê°€")
    print("   dt=0.05ë¡œ ì¡°ì •")
    print("   â†’ í•™ìŠµ ë°ì´í„° ìŠ¤ì¼€ì¼ì— ê·¼ì ‘í•œ ì„±ëŠ¥ ê¸°ëŒ€")

if __name__ == "__main__":
    print("ğŸš€ ëª¨ë¸ ì¶œë ¥ ìŠ¤ì¼€ì¼ ë¬¸ì œ í•´ê²°ì±… ë¶„ì„")
    print()
    
    # 1. dt ì¡°ì • í…ŒìŠ¤íŠ¸
    dt_results = solution_1_scale_dt()
    
    # 2. velocity ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸  
    scale_results = solution_2_velocity_scaling()
    
    # 3. ì ì‘ì  ì¶”ë¡  í…ŒìŠ¤íŠ¸
    adaptive_results = solution_3_adaptive_inference()
    
    # 4. ìµœì  í•´ê²°ì±… ì¶”ì²œ
    recommend_best_solution()
    
    print("\nâœ… ëª¨ë“  í•´ê²°ì±… ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“ ë‹¤ìŒ ë‹¨ê³„: ì„ íƒí•œ í•´ê²°ì±… êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸")

