#!/usr/bin/env python3
"""
SE(3) Trajectory Pipeline Test & Validation
Complete integration test for SE(3) trajectory processing pipeline
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys
import traceback

# Add paths
sys.path.append('/Users/a123/Documents/Projects/2D_sim/packages/utils')
sys.path.append('/Users/a123/Documents/Projects/2D_sim/packages/data_generator/loaders')
sys.path.append('/Users/a123/Documents/Projects/2D_sim/packages/data_generator/hdf5_tools')

from SE3_functions import (
    traj_smooth_se3_bspline_slerp,
    traj_process_se3_pipeline,
    traj_build_labels_with_policy,
    traj_integrate_by_twist,
    _se3_exp,
    _se3_log,
    euler_6d_to_quaternion_7d,
    trajectory_euler_to_quaternion
)

try:
    from se3_trajectory_dataset import SE3TrajectoryDataset
    DATASET_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Dataset import failed: {e}")
    DATASET_AVAILABLE = False

try:
    from hdf5_trajectory_loader import HDF5TrajectoryLoader
    HDF5_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ HDF5 loader import failed: {e}")
    HDF5_AVAILABLE = False


def generate_test_se3_trajectory(N: int = 100) -> torch.Tensor:
    """í…ŒìŠ¤íŠ¸ìš© SE(3) ê¶¤ì  ìƒì„±"""
    print("ğŸ“Š Generating test SE(3) trajectory...")
    
    # ì›í˜• ê¶¤ì  ìƒì„±
    t = torch.linspace(0, 2*np.pi, N)
    radius = 2.0
    height_variation = 0.5
    
    # ìœ„ì¹˜: ë‚˜ì„ í˜•
    positions = torch.zeros(N, 3)
    positions[:, 0] = radius * torch.cos(t)  # x
    positions[:, 1] = radius * torch.sin(t)  # y  
    positions[:, 2] = height_variation * torch.sin(2*t)  # z (ë†’ì´ ë³€í™”)
    
    # íšŒì „: ê¶¤ì  ë°©í–¥ì„ ë”°ë¼ íšŒì „
    rotations = torch.zeros(N, 3, 3)
    for i in range(N):
        # Forward direction (tangent)
        if i < N-1:
            forward = positions[i+1] - positions[i]
        else:
            forward = positions[i] - positions[i-1]
        forward = forward / torch.norm(forward)
        
        # Up direction
        up = torch.tensor([0., 0., 1.])
        
        # Right direction (cross product)
        right = torch.cross(forward, up)
        right = right / torch.norm(right)
        
        # Recompute up to make orthonormal
        up = torch.cross(right, forward)
        
        # Build rotation matrix
        R = torch.stack([right, up, forward], dim=1)  # Column vectors
        rotations[i] = R
    
    # SE(3) í–‰ë ¬ êµ¬ì„±
    T_traj = torch.eye(4).unsqueeze(0).repeat(N, 1, 1)
    T_traj[:, :3, :3] = rotations
    T_traj[:, :3, 3] = positions
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ ì‹¤ì œì ì¸ ê¶¤ì  ìƒì„±
    position_noise = torch.randn_like(positions) * 0.05
    T_traj[:, :3, 3] += position_noise
    
    print(f"   Generated {N} SE(3) poses")
    return T_traj


def test_se3_functions():
    """SE(3) í•¨ìˆ˜ë“¤ ê°œë³„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Testing SE(3) functions individually...")
    
    # í…ŒìŠ¤íŠ¸ ê¶¤ì  ìƒì„±
    T_raw = generate_test_se3_trajectory(50)
    print(f"   Input trajectory shape: {T_raw.shape}")
    
    try:
        # 1) ìŠ¤ë¬´ë”© í…ŒìŠ¤íŠ¸
        print("\nğŸ”§ Testing SE(3) smoothing...")
        T_smooth = traj_smooth_se3_bspline_slerp(T_raw, smooth=0.1)
        print(f"   âœ… Smoothing: {T_raw.shape} â†’ {T_smooth.shape}")
        
        # ìŠ¤ë¬´ë”© íš¨ê³¼ ê²€ì¦ (ìœ„ì¹˜ ì°¨ì´ í‰ê· )
        pos_diff_before = torch.mean(torch.norm(T_raw[1:, :3, 3] - T_raw[:-1, :3, 3], dim=-1))
        pos_diff_after = torch.mean(torch.norm(T_smooth[1:, :3, 3] - T_smooth[:-1, :3, 3], dim=-1))
        print(f"   Position smoothness: {pos_diff_before:.4f} â†’ {pos_diff_after:.4f}")
        
    except Exception as e:
        print(f"   âŒ Smoothing failed: {e}")
        return False
    
    try:
        # 2) ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        print("\nğŸ”§ Testing complete SE(3) pipeline...")
        T_processed, dt_seq, xi_labels, T_smooth_pipeline = traj_process_se3_pipeline(
            T_raw,
            smooth_first=True,
            num_samples=30,
            policy="curvature"
        )
        
        print(f"   âœ… Pipeline results:")
        print(f"      Processed trajectory: {T_processed.shape}")
        print(f"      Time sequence: {dt_seq.shape}")
        print(f"      Body twist labels: {xi_labels.shape}")
        print(f"      Smoothed trajectory: {T_smooth_pipeline.shape}")
        
        # ë¬¼ë¦¬ì  íƒ€ë‹¹ì„± ê²€ì¦
        dt_mean = torch.mean(dt_seq)
        dt_std = torch.std(dt_seq)
        xi_norm_mean = torch.mean(torch.norm(xi_labels, dim=-1))
        
        print(f"      Average dt: {dt_mean:.4f} Â± {dt_std:.4f}")
        print(f"      Average twist magnitude: {xi_norm_mean:.4f}")
        
    except Exception as e:
        print(f"   âŒ Pipeline failed: {e}")
        return False
    
    try:
        # 3) ì ë¶„ ê²€ì¦
        print("\nğŸ”§ Testing trajectory integration...")
        T0 = T_processed[0]
        xi_seq = xi_labels[:-1]  # ë§ˆì§€ë§‰ ì œì™¸ (0ìœ¼ë¡œ íŒ¨ë”©ë¨)
        dt_seq_for_integration = dt_seq
        
        T_integrated = traj_integrate_by_twist(T0, xi_seq, dt_seq_for_integration)
        print(f"   âœ… Integration: {T0.shape} â†’ {T_integrated.shape}")
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ ì¸¡ì •
        position_error = torch.mean(torch.norm(
            T_integrated[1:, :3, 3] - T_processed[1:, :3, 3], dim=-1
        ))
        print(f"      Position reconstruction error: {position_error:.6f}")
        
        if position_error < 0.1:  # í—ˆìš© ì˜¤ì°¨
            print("   âœ… Integration accuracy: GOOD")
        else:
            print("   âš ï¸ Integration accuracy: MODERATE")
        
    except Exception as e:
        print(f"   âŒ Integration failed: {e}")
        return False
    
    return True


def test_format_conversions():
    """í¬ë§· ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”„ Testing format conversions...")
    
    try:
        # 6D Euler â†’ 7D Quaternion ë³€í™˜
        test_6d = np.array([1.0, 2.0, 3.0, 0.1, 0.2, 0.3])  # [x,y,z,rx,ry,rz]
        test_7d = euler_6d_to_quaternion_7d(test_6d)
        print(f"   6D â†’ 7D: {test_6d.shape} â†’ {test_7d.shape}")
        print(f"      6D: {test_6d}")
        print(f"      7D: {test_7d}")
        
        # ê¶¤ì  ë³€í™˜ í…ŒìŠ¤íŠ¸
        traj_6d = np.random.randn(10, 6)
        traj_7d = trajectory_euler_to_quaternion(traj_6d)
        print(f"   Trajectory conversion: {traj_6d.shape} â†’ {traj_7d.shape}")
        
        print("   âœ… Format conversions: PASSED")
        
    except Exception as e:
        print(f"   âŒ Format conversions failed: {e}")
        return False
    
    return True


def test_dataset_integration():
    """ë°ì´í„°ì…‹ í†µí•© í…ŒìŠ¤íŠ¸"""
    if not DATASET_AVAILABLE:
        print("\nâš ï¸ Skipping dataset test (import failed)")
        return True
    
    print("\nğŸ“¦ Testing SE3TrajectoryDataset integration...")
    
    # HDF5 íŒŒì¼ ê²½ë¡œ í™•ì¸
    test_hdf5_path = Path("/Users/a123/Documents/Projects/2D_sim/packages/data_generator/test_trajectory_dataset.h5")
    
    if not test_hdf5_path.exists():
        print(f"   âš ï¸ Test HDF5 file not found: {test_hdf5_path}")
        print("   Run hdf5_schema_creator.py first to create test data")
        return True  # í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° (ì‹¤íŒ¨ ì•„ë‹˜)
    
    try:
        # ë°ì´í„°ì…‹ ìƒì„±
        config = {
            'use_smoothing': True,
            'smooth_strength': 0.1,
            'num_samples': 30,
            'augmentation': False,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë¹„í™œì„±í™”
            'max_trajectories': 3   # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì œí•œ
        }
        
        print("   Creating dataset...")
        dataset = SE3TrajectoryDataset(str(test_hdf5_path), split='train', **config)
        print(f"   âœ… Dataset created with {len(dataset)} trajectories")
        
        if len(dataset) > 0:
            # ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸
            print("   Testing sample data...")
            sample = dataset[0]
            
            expected_keys = ['T_processed', 'xi_labels', 'dt_seq', 'T_raw', 'T_smooth', 'metadata']
            for key in expected_keys:
                if key not in sample:
                    print(f"   âŒ Missing key: {key}")
                    return False
                
            print(f"   âœ… Sample data keys: {list(sample.keys())}")
            
            # ë°ì´í„° í˜•íƒœ ê²€ì¦
            T_processed = sample['T_processed']
            xi_labels = sample['xi_labels']
            dt_seq = sample['dt_seq']
            
            print(f"      T_processed: {T_processed.shape}")
            print(f"      xi_labels: {xi_labels.shape}")
            print(f"      dt_seq: {dt_seq.shape}")
            
            # ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
            M = T_processed.shape[0]
            if xi_labels.shape[0] != M:
                print(f"   âŒ Inconsistent shapes: T_processed[{M}] vs xi_labels[{xi_labels.shape[0]}]")
                return False
            
            if dt_seq.shape[0] != M - 1:
                print(f"   âŒ Inconsistent dt_seq shape: expected {M-1}, got {dt_seq.shape[0]}")
                return False
            
            # DataLoader í…ŒìŠ¤íŠ¸
            print("   Testing DataLoader...")
            dataloader = dataset.get_dataloader(batch_size=2, num_workers=0)  # num_workers=0 for debugging
            
            batch = next(iter(dataloader))
            print(f"   âœ… Batch created with keys: {list(batch.keys())}")
            
            # ë°°ì¹˜ í¬ê¸° ê²€ì¦
            batch_size = len(batch['metadata'])
            print(f"      Batch size: {batch_size}")
            
            for key, value in batch.items():
                if isinstance(value, torch.Tensor):
                    print(f"      {key}: {value.shape}")
        
        dataset.close()
        print("   âœ… Dataset integration: PASSED")
        
    except Exception as e:
        print(f"   âŒ Dataset integration failed: {e}")
        traceback.print_exc()
        return False
    
    return True


def visualize_pipeline_results():
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì‹œê°í™”"""
    print("\nğŸ“Š Creating pipeline visualization...")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        T_raw = generate_test_se3_trajectory(60)
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        T_processed, dt_seq, xi_labels, T_smooth = traj_process_se3_pipeline(
            T_raw,
            smooth_first=True,
            smooth=0.2,
            num_samples=40,
            policy="curvature"
        )
        
        # í”Œë¡¯ ìƒì„±
        fig = plt.figure(figsize=(15, 10))
        
        # 1) ìœ„ì¹˜ ê¶¤ì  ë¹„êµ
        ax1 = fig.add_subplot(2, 3, 1, projection='3d')
        
        pos_raw = T_raw[:, :3, 3].numpy()
        pos_smooth = T_smooth[:, :3, 3].numpy() if T_smooth is not None else pos_raw
        pos_processed = T_processed[:, :3, 3].numpy()
        
        ax1.plot(pos_raw[:, 0], pos_raw[:, 1], pos_raw[:, 2], 'r.-', label='Raw', alpha=0.7)
        ax1.plot(pos_smooth[:, 0], pos_smooth[:, 1], pos_smooth[:, 2], 'g-', label='Smoothed', linewidth=2)
        ax1.plot(pos_processed[:, 0], pos_processed[:, 1], pos_processed[:, 2], 'b.-', label='Processed', alpha=0.8)
        
        ax1.set_title('SE(3) Position Trajectories')
        ax1.set_xlabel('X')
        ax1.set_ylabel('Y')
        ax1.set_zlabel('Z')
        ax1.legend()
        
        # 2) ì‹œê°„ ê°„ê²©
        ax2 = fig.add_subplot(2, 3, 2)
        ax2.plot(dt_seq.numpy(), 'b.-')
        ax2.set_title('Time Intervals (dt)')
        ax2.set_xlabel('Segment')
        ax2.set_ylabel('dt')
        ax2.grid(True)
        
        # 3) Body twist í¬ê¸°
        ax3 = fig.add_subplot(2, 3, 3)
        xi_norms = torch.norm(xi_labels, dim=-1).numpy()
        ax3.plot(xi_norms, 'g.-')
        ax3.set_title('Body Twist Magnitude')
        ax3.set_xlabel('Time Step')
        ax3.set_ylabel('||Î¾||')
        ax3.grid(True)
        
        # 4) Body twist êµ¬ì„±ìš”ì†Œ
        ax4 = fig.add_subplot(2, 3, 4)
        xi_np = xi_labels.numpy()
        for i in range(6):
            label = ['Ï‰x', 'Ï‰y', 'Ï‰z', 'vx', 'vy', 'vz'][i]
            ax4.plot(xi_np[:, i], label=label, alpha=0.7)
        ax4.set_title('Body Twist Components')
        ax4.set_xlabel('Time Step')
        ax4.set_ylabel('Value')
        ax4.legend()
        ax4.grid(True)
        
        # 5) ìœ„ì¹˜ ì†ë„
        ax5 = fig.add_subplot(2, 3, 5)
        velocities = torch.norm(xi_labels[:, 3:], dim=-1).numpy()
        ax5.plot(velocities, 'm.-')
        ax5.set_title('Linear Velocity')
        ax5.set_xlabel('Time Step')
        ax5.set_ylabel('||v||')
        ax5.grid(True)
        
        # 6) ê°ì†ë„
        ax6 = fig.add_subplot(2, 3, 6)
        angular_velocities = torch.norm(xi_labels[:, :3], dim=-1).numpy()
        ax6.plot(angular_velocities, 'c.-')
        ax6.set_title('Angular Velocity')
        ax6.set_xlabel('Time Step')
        ax6.set_ylabel('||Ï‰||')
        ax6.grid(True)
        
        plt.tight_layout()
        
        # ì €ì¥
        output_path = Path("se3_pipeline_results.png")
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ… Visualization saved to: {output_path}")
        
    except Exception as e:
        print(f"   âŒ Visualization failed: {e}")
        return False
    
    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ SE(3) Trajectory Pipeline Comprehensive Test")
    print("=" * 60)
    
    tests = [
        ("SE(3) Functions", test_se3_functions),
        ("Format Conversions", test_format_conversions),
        ("Dataset Integration", test_dataset_integration),
        ("Pipeline Visualization", visualize_pipeline_results)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} failed with exception: {e}")
            traceback.print_exc()
            results[test_name] = False
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print("ğŸ“‹ TEST SUMMARY")
    print("=" * 60)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ… PASSED" if passed else "âŒ FAILED"
        print(f"   {test_name:<25}: {status}")
        if not passed:
            all_passed = False
    
    print("=" * 60)
    if all_passed:
        print("ğŸ‰ ALL TESTS PASSED! SE(3) pipeline is ready for use.")
    else:
        print("âš ï¸ Some tests failed. Check the output above for details.")
    
    print("\nğŸ’¡ Next Steps:")
    print("   1. Create HDF5 test data if needed: python hdf5_schema_creator.py")
    print("   2. Use SE3TrajectoryDataset in your training code")
    print("   3. Integrate with your ML model training pipeline")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)