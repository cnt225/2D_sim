#!/usr/bin/env python3
"""
HDF5 Schema Creator
Plan.mdì— ë”°ë¥¸ HDF5 ìŠ¤í‚¤ë§ˆ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬

HDF5 êµ¬ì¡°:
trajectory_dataset.h5
â”œâ”€â”€ metadata/                 # ë©”íƒ€ë°ì´í„°
â”‚   â”œâ”€â”€ schema_info/         # ìŠ¤í‚¤ë§ˆ ì •ë³´
â”‚   â”œâ”€â”€ environments/        # í™˜ê²½ ì •ë³´
â”‚   â”œâ”€â”€ rigid_bodies/        # ë¡œë´‡ ì •ë³´
â”‚   â””â”€â”€ generation_settings/ # ìƒì„± ì„¤ì •
â”œâ”€â”€ pose_pairs/              # í™˜ê²½ë³„ pose pair ë°ì´í„°
â”‚   â”œâ”€â”€ circle_env_000000/
â”‚   â”‚   â””â”€â”€ pairs: [N, 2, 7] # init/target pose [x,y,z,qw,qx,qy,qz]
â”‚   â””â”€â”€ ...
â”œâ”€â”€ trajectories/            # ê¶¤ì  ë°ì´í„°
â”‚   â”œâ”€â”€ raw/                 # ì›ë³¸ RRT ê¶¤ì 
â”‚   â”œâ”€â”€ bsplined/           # B-spline ìŠ¤ë¬´ë”©ëœ ê¶¤ì 
â”‚   â””â”€â”€ derivatives/        # ì†ë„, ê°€ì†ë„ ë“± íŒŒìƒ ë°ì´í„°
â””â”€â”€ indices/                # ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤
"""

import h5py
import numpy as np
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime


def create_hdf5_schema(hdf5_path: str, overwrite: bool = False) -> h5py.File:
    """
    ë¹ˆ HDF5 ìŠ¤í‚¤ë§ˆ ìƒì„±
    
    Args:
        hdf5_path: HDF5 íŒŒì¼ ê²½ë¡œ
        overwrite: ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° ì—¬ë¶€
    
    Returns:
        h5py.File: ì—´ë¦° HDF5 íŒŒì¼ ê°ì²´
    """
    hdf5_path = Path(hdf5_path)
    
    # ê¸°ì¡´ íŒŒì¼ ì²´í¬
    if hdf5_path.exists() and not overwrite:
        print(f"âš ï¸ HDF5 file already exists: {hdf5_path}")
        print("   Use overwrite=True to recreate")
        return h5py.File(hdf5_path, 'a')  # append mode
    
    # Create directory if needed
    hdf5_path.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸš€ Creating HDF5 schema: {hdf5_path}")
    
    # Create HDF5 file
    hdf5_file = h5py.File(hdf5_path, 'w')
    
    # === 1. Metadata ê·¸ë£¹ ìƒì„± ===
    metadata_group = hdf5_file.create_group('metadata')
    
    # Schema info
    schema_group = metadata_group.create_group('schema_info')
    schema_group.attrs['version'] = '1.0.0'
    schema_group.attrs['format'] = 'quaternion_7d'
    schema_group.attrs['created'] = datetime.now().isoformat()
    schema_group.attrs['description'] = 'HDF5-based trajectory dataset with quaternion representation'
    
    # Environments
    env_group = metadata_group.create_group('environments')
    env_group.attrs['description'] = 'Environment metadata and configurations'
    
    # Rigid bodies
    rb_group = metadata_group.create_group('rigid_bodies')
    rb_group.attrs['description'] = 'Rigid body configurations and parameters'
    
    # Generation settings
    gen_group = metadata_group.create_group('generation_settings')
    gen_group.attrs['description'] = 'Trajectory generation parameters and settings'
    
    # === 2. Pose pairs ê·¸ë£¹ ìƒì„± ===
    pairs_group = hdf5_file.create_group('pose_pairs')
    pairs_group.attrs['format'] = '[N, 2, 7]'
    pairs_group.attrs['description'] = 'Pose pairs in 7D quaternion format [x,y,z,qw,qx,qy,qz]'
    
    # === 3. Trajectories ê·¸ë£¹ ìƒì„± ===
    traj_group = hdf5_file.create_group('trajectories')
    
    # Raw trajectories (original RRT output)
    raw_group = traj_group.create_group('raw')
    raw_group.attrs['format'] = '[N, 7]'
    raw_group.attrs['description'] = 'Raw RRT trajectories in 7D quaternion format'
    
    # B-splined trajectories
    bsplined_group = traj_group.create_group('bsplined')
    bsplined_group.attrs['format'] = '[N, 7]'
    bsplined_group.attrs['description'] = 'B-spline smoothed trajectories with quaternion SLERP'
    
    # Derivative data
    deriv_group = traj_group.create_group('derivatives')
    deriv_group.attrs['description'] = 'Velocity, acceleration and other derivative data'
    
    # === 4. Indices ê·¸ë£¹ ìƒì„± ===
    index_group = hdf5_file.create_group('indices')
    index_group.attrs['description'] = 'Indexing data for fast trajectory lookup'
    
    # Environment index
    env_idx = index_group.create_dataset('environment_index', (0,), maxshape=(None,), 
                                        dtype=h5py.string_dtype(encoding='utf-8'))
    env_idx.attrs['description'] = 'Environment ID to HDF5 path mapping'
    
    # Success/failure index
    success_idx = index_group.create_dataset('success_index', (0, 2), maxshape=(None, 2),
                                           dtype='bool')
    success_idx.attrs['description'] = 'Success status [environment_idx, trajectory_idx]'
    
    print(f"âœ… HDF5 schema created successfully")
    print(f"   Structure: metadata/, pose_pairs/, trajectories/, indices/")
    
    return hdf5_file


def add_environment_metadata(hdf5_file: h5py.File, env_data: Dict[str, Any]) -> None:
    """
    í™˜ê²½ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    
    Args:
        hdf5_file: HDF5 íŒŒì¼ ê°ì²´
        env_data: í™˜ê²½ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            {
                'env_id': 'circle_env_000000',
                'name': 'Circle Environment',
                'description': 'Circular obstacles',
                'ply_file': 'path/to/env.ply',
                'bounds': [x_min, x_max, y_min, y_max],
                'obstacles': [...],
                'difficulty': 'medium'
            }
    """
    required_fields = ['env_id', 'name']
    if not all(field in env_data for field in required_fields):
        raise ValueError(f"Environment data must contain: {required_fields}")
    
    env_id = env_data['env_id']
    env_group = hdf5_file['metadata/environments']
    
    # Create environment subgroup
    if env_id in env_group:
        print(f"âš ï¸ Environment {env_id} already exists, updating...")
        del env_group[env_id]
    
    env_subgroup = env_group.create_group(env_id)
    
    # Add metadata as attributes
    for key, value in env_data.items():
        if isinstance(value, (str, int, float, bool)):
            env_subgroup.attrs[key] = value
        elif isinstance(value, (list, np.ndarray)):
            # Store arrays as datasets
            env_subgroup.create_dataset(key, data=np.array(value))
        else:
            # Convert complex types to JSON strings
            env_subgroup.attrs[key] = json.dumps(value)
    
    env_subgroup.attrs['added_timestamp'] = datetime.now().isoformat()
    
    print(f"âœ… Environment metadata added: {env_id}")


def add_rigid_body_metadata(hdf5_file: h5py.File, rb_data: Dict[str, Any]) -> None:
    """
    ë¡œë´‡ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    
    Args:
        hdf5_file: HDF5 íŒŒì¼ ê°ì²´
        rb_data: ë¡œë´‡ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            {
                'rigid_body_id': 3,
                'name': 'EndEffector',
                'type': 'elongated_ellipse',
                'dimensions': [length, width, height],
                'mass': 1.0,
                'collision_model': 'ellipsoid',
                'dof': 3,
                'description': 'SE(3) rigid body with elongated ellipse shape'
            }
    """
    required_fields = ['rigid_body_id', 'name', 'type']
    if not all(field in rb_data for field in required_fields):
        raise ValueError(f"Rigid body data must contain: {required_fields}")
    
    rb_id = f"rb_{rb_data['rigid_body_id']}"
    rb_group = hdf5_file['metadata/rigid_bodies']
    
    # Create rigid body subgroup
    if rb_id in rb_group:
        print(f"âš ï¸ Rigid body {rb_id} already exists, updating...")
        del rb_group[rb_id]
    
    rb_subgroup = rb_group.create_group(rb_id)
    
    # Add metadata as attributes
    for key, value in rb_data.items():
        if isinstance(value, (str, int, float, bool)):
            rb_subgroup.attrs[key] = value
        elif isinstance(value, (list, np.ndarray)):
            # Store arrays as datasets
            rb_subgroup.create_dataset(key, data=np.array(value))
        else:
            # Convert complex types to JSON strings
            rb_subgroup.attrs[key] = json.dumps(value)
    
    rb_subgroup.attrs['added_timestamp'] = datetime.now().isoformat()
    
    print(f"âœ… Rigid body metadata added: {rb_id}")


def add_generation_settings(hdf5_file: h5py.File, settings: Dict[str, Any]) -> None:
    """
    ê¶¤ì  ìƒì„± ì„¤ì • ì¶”ê°€
    
    Args:
        hdf5_file: HDF5 íŒŒì¼ ê°ì²´
        settings: ìƒì„± ì„¤ì •
            {
                'planner': 'RRT-Connect',
                'max_planning_time': 5.0,
                'range': 0.1,
                'goal_bias': 0.05,
                'bspline_degree': 3,
                'conversion': '6d_to_7d'
            }
    """
    gen_group = hdf5_file['metadata/generation_settings']
    
    # Add current timestamp
    settings['generation_timestamp'] = datetime.now().isoformat()
    
    # Store settings
    for key, value in settings.items():
        if isinstance(value, (str, int, float, bool)):
            gen_group.attrs[key] = value
        elif isinstance(value, (list, np.ndarray)):
            gen_group.create_dataset(key, data=np.array(value))
        else:
            gen_group.attrs[key] = json.dumps(value)
    
    print(f"âœ… Generation settings added")


def create_pose_pair_group(hdf5_file: h5py.File, env_id: str, pose_pairs_data: np.ndarray) -> None:
    """
    í™˜ê²½ë³„ pose pair ê·¸ë£¹ ìƒì„±
    
    Args:
        hdf5_file: HDF5 íŒŒì¼ ê°ì²´
        env_id: í™˜ê²½ ID (ì˜ˆ: 'circle_env_000000')
        pose_pairs_data: [N, 2, 7] í˜•íƒœì˜ pose pairs ë°ì´í„°
    """
    pairs_group = hdf5_file['pose_pairs']
    
    if env_id in pairs_group:
        print(f"âš ï¸ Pose pairs for {env_id} already exist, updating...")
        del pairs_group[env_id]
    
    env_pair_group = pairs_group.create_group(env_id)
    
    # Validate data format
    if len(pose_pairs_data.shape) != 3 or pose_pairs_data.shape[1:] != (2, 7):
        raise ValueError(f"Expected [N, 2, 7] pose pairs, got shape {pose_pairs_data.shape}")
    
    # Store pose pairs
    pairs_dataset = env_pair_group.create_dataset('pairs', data=pose_pairs_data, 
                                                 compression='gzip', compression_opts=6)
    pairs_dataset.attrs['format'] = '[x, y, z, qw, qx, qy, qz]'
    pairs_dataset.attrs['description'] = 'Initial and target poses in 7D quaternion format'
    pairs_dataset.attrs['count'] = pose_pairs_data.shape[0]
    pairs_dataset.attrs['added_timestamp'] = datetime.now().isoformat()
    
    print(f"âœ… Pose pairs added for {env_id}: {pose_pairs_data.shape[0]} pairs")


def validate_hdf5_schema(hdf5_path: str) -> bool:
    """
    HDF5 ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦
    
    Args:
        hdf5_path: HDF5 íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ìŠ¤í‚¤ë§ˆê°€ ìœ íš¨í•œì§€ ì—¬ë¶€
    """
    try:
        with h5py.File(hdf5_path, 'r') as f:
            # Required groups
            required_groups = [
                'metadata',
                'metadata/schema_info',
                'metadata/environments', 
                'metadata/rigid_bodies',
                'metadata/generation_settings',
                'pose_pairs',
                'trajectories',
                'trajectories/raw',
                'trajectories/bsplined',
                'trajectories/derivatives',
                'indices'
            ]
            
            for group_path in required_groups:
                if group_path not in f:
                    print(f"âŒ Missing required group: {group_path}")
                    return False
            
            # Check schema version
            if 'version' not in f['metadata/schema_info'].attrs:
                print(f"âŒ Missing schema version")
                return False
            
            print(f"âœ… HDF5 schema validation passed")
            return True
            
    except Exception as e:
        print(f"âŒ HDF5 schema validation failed: {e}")
        return False


if __name__ == "__main__":
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª Testing HDF5 Schema Creator")
    
    # Test schema creation
    test_hdf5_path = "test_trajectory_dataset.h5"
    
    try:
        # Create schema
        hdf5_file = create_hdf5_schema(test_hdf5_path, overwrite=True)
        
        # Add sample environment metadata
        env_data = {
            'env_id': 'circle_env_000000',
            'name': 'Circle Test Environment',
            'description': 'Test environment with circular obstacles',
            'ply_file': 'data/environments/circles.ply',
            'bounds': [-5.0, 5.0, -5.0, 5.0],
            'difficulty': 'medium'
        }
        add_environment_metadata(hdf5_file, env_data)
        
        # Add sample rigid body metadata
        rb_data = {
            'rigid_body_id': 3,
            'name': 'TestEndEffector',
            'type': 'elongated_ellipse',
            'dimensions': [0.2, 0.1, 0.05],
            'mass': 1.0,
            'collision_model': 'ellipsoid',
            'dof': 3
        }
        add_rigid_body_metadata(hdf5_file, rb_data)
        
        # Add generation settings
        settings = {
            'planner': 'RRT-Connect',
            'max_planning_time': 5.0,
            'conversion': '6d_to_7d'
        }
        add_generation_settings(hdf5_file, settings)
        
        # Close file
        hdf5_file.close()
        
        # Validate schema
        if validate_hdf5_schema(test_hdf5_path):
            print(f"âœ… Test completed successfully: {test_hdf5_path}")
        else:
            print(f"âŒ Schema validation failed")
            
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()