#!/usr/bin/env python3
"""
ğŸš€ í†µí•© Trajectory Smoothing System
ê¸°ì¡´ raw trajectory HDF5 íŒŒì¼ì„ ì½ì–´ì„œ ìŠ¤ë¬´ë”©ëœ ìƒˆ HDF5 íŒŒì¼ ìƒì„±
- SE(3) B-spline + SLERP ìŠ¤ë¬´ë”© ì§€ì›
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²­í¬ ì²˜ë¦¬
- ì•ˆì „í•œ íŒŒì¼ ê´€ë¦¬ (ì…ë ¥ â†’ ìƒˆ ì¶œë ¥)

ì‚¬ìš©ë²•:
    # ì „ì²´ íŒŒì¼ ìŠ¤ë¬´ë”© (ê¶Œì¥)
    python batch_smooth_trajectories.py --input circles_only_trajs.h5 --output circles_only_smooth.h5
    
    # ë©”ëª¨ë¦¬ ì œí•œ í™˜ê²½ì—ì„œ
    python batch_smooth_trajectories.py --input large_file.h5 --output smooth_file.h5 --chunk-size 10
"""

import os
import sys
import argparse
import time
import gc
import psutil
import numpy as np
import torch
import h5py
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / 'packages'))

# SE(3) í•¨ìˆ˜ import
from packages.utils.SE3_functions import (
    traj_smooth_se3_bspline_slerp,
    traj_resample_by_arclength
)


class IntegratedTrajectorySmoother:
    """
    í†µí•© ê¶¤ì  ìŠ¤ë¬´ë”© ì‹œìŠ¤í…œ
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²­í¬ ì²˜ë¦¬
    - SE(3) B-spline + SLERP ìŠ¤ë¬´ë”©
    - ì•ˆì „í•œ íŒŒì¼ ê´€ë¦¬
    """
    
    def __init__(self, input_file: str, output_file: str, chunk_size: int = 20, 
                 memory_threshold: float = 75.0, verbose: bool = False, output_format: str = 'se3_6d'):
        """
        Args:
            input_file: ì…ë ¥ HDF5 íŒŒì¼ ê²½ë¡œ
            output_file: ì¶œë ¥ HDF5 íŒŒì¼ ê²½ë¡œ
            chunk_size: í™˜ê²½ ì²­í¬ í¬ê¸°
            memory_threshold: ë©”ëª¨ë¦¬ ê²½ê³  ì„ê³„ê°’ (%)
            verbose: ìƒì„¸ ì¶œë ¥
            output_format: ê¶¤ì  ì¶œë ¥ í˜•ì‹ ('se2', 'se3', 'se3_6d', 'quaternion_7d')
        """
        self.input_file = Path(input_file)
        self.output_file = Path(output_file)
        self.chunk_size = chunk_size
        self.memory_threshold = memory_threshold
        self.verbose = verbose
        
        # ì¶œë ¥ í˜•ì‹ ê²€ì¦
        valid_formats = ['se2', 'se3', 'se3_6d', 'quaternion_7d']
        if output_format not in valid_formats:
            raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ í˜•ì‹: {output_format}. ì§€ì› í˜•ì‹: {valid_formats}")
        self.output_format = output_format
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # í†µê³„
        self.stats = {
            'total_environments': 0,
            'processed_environments': 0,
            'total_trajectories': 0,
            'successful_smoothing': 0,
            'failed_smoothing': 0,
            'processing_time': 0.0,
            'memory_warnings': 0
        }
        
        print(f"ğŸš€ í†µí•© ê¶¤ì  ìŠ¤ë¬´ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ì…ë ¥: {self.input_file}")
        print(f"   ì¶œë ¥: {self.output_file}")
        print(f"   ì²­í¬ í¬ê¸°: {chunk_size}")
        print(f"   ë©”ëª¨ë¦¬ ì„ê³„ê°’: {memory_threshold}%")
    
    def _get_memory_usage(self) -> Tuple[float, float, float]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB, %, GPU MB)"""
        process = psutil.Process()
        cpu_mb = process.memory_info().rss / 1024 / 1024
        system_percent = psutil.virtual_memory().percent
        
        gpu_mb = 0.0
        if torch.cuda.is_available():
            gpu_mb = torch.cuda.memory_allocated() / 1024 / 1024
        
        return cpu_mb, system_percent, gpu_mb
    
    def _convert_trajectory_format(self, T_matrices: torch.Tensor, format_type: str) -> np.ndarray:
        """ê¶¤ì ì„ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        T_np = T_matrices.cpu().numpy() if isinstance(T_matrices, torch.Tensor) else T_matrices
        N = T_np.shape[0]
        
        if format_type == 'se2':
            # SE(2) [x, y, yaw]
            result = np.zeros((N, 3))
            for i in range(N):
                result[i, 0] = T_np[i, 0, 3]  # x
                result[i, 1] = T_np[i, 1, 3]  # y
                result[i, 2] = np.arctan2(T_np[i, 1, 0], T_np[i, 0, 0])  # yaw
            return result
            
        elif format_type == 'se3':
            # SE(3) 4x4 í–‰ë ¬ ê·¸ëŒ€ë¡œ
            return T_np
            
        elif format_type == 'se3_6d':
            # SE(3) 6D [x, y, z, rx, ry, rz]
            result = np.zeros((N, 6))
            for i in range(N):
                result[i, 0] = T_np[i, 0, 3]  # x
                result[i, 1] = T_np[i, 1, 3]  # y
                result[i, 2] = T_np[i, 2, 3]  # z
                result[i, 3] = 0.0  # roll (ê³ ì •)
                result[i, 4] = 0.0  # pitch (ê³ ì •)
                result[i, 5] = np.arctan2(T_np[i, 1, 0], T_np[i, 0, 0])  # yaw
            return result
            
        elif format_type == 'quaternion_7d':
            # ì¿¼í„°ë‹ˆì–¸ 7D [x, y, z, qw, qx, qy, qz]
            from packages.utils.SE3_functions import trajectory_euler_to_quaternion
            # ë¨¼ì € 6Dë¡œ ë³€í™˜ í›„ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ
            se3_6d = self._convert_trajectory_format(T_matrices, 'se3_6d')
            result = trajectory_euler_to_quaternion(se3_6d)
            return result
            
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format_type}")

    def _monitor_memory(self, context: str = "") -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ê²½ê³ """
        cpu_mb, system_percent, gpu_mb = self._get_memory_usage()
        
        if self.verbose:
            print(f"   ğŸ’¾ ë©”ëª¨ë¦¬ {context}: CPU {cpu_mb:.1f}MB, ì‹œìŠ¤í…œ {system_percent:.1f}%, GPU {gpu_mb:.1f}MB")
        
        if system_percent > self.memory_threshold:
            print(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {system_percent:.1f}%")
            self.stats['memory_warnings'] += 1
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    def _se3_smooth_trajectory(self, raw_traj: np.ndarray) -> Tuple[Optional[np.ndarray], Dict[str, Any]]:
        """
        SE(3) ë°©ì‹ìœ¼ë¡œ ê¶¤ì  ìŠ¤ë¬´ë”©
        
        Args:
            raw_traj: SE(2) ê¶¤ì  (N, 3) [x, y, yaw]
            
        Returns:
            (smoothed_traj, stats): ìŠ¤ë¬´ë”©ëœ ê¶¤ì ê³¼ í†µê³„
        """
        try:
            if self.verbose:
                print(f"      ğŸ”§ ì…ë ¥ ê¶¤ì : {raw_traj.shape}, ë²”ìœ„: x[{raw_traj[:, 0].min():.2f}-{raw_traj[:, 0].max():.2f}], y[{raw_traj[:, 1].min():.2f}-{raw_traj[:, 1].max():.2f}], yaw[{raw_traj[:, 2].min():.2f}-{raw_traj[:, 2].max():.2f}]")
            
            # ì…ë ¥ ê²€ì¦
            if len(raw_traj) < 2:
                raise ValueError(f"ê¶¤ì  í¬ì¸íŠ¸ ë¶€ì¡±: {len(raw_traj)}ê°œ")
            
            if raw_traj.shape[1] != 3:
                raise ValueError(f"ì˜ëª»ëœ í˜•íƒœ: {raw_traj.shape}, 3ì—´ í•„ìš”")
            
            if np.any(np.isnan(raw_traj)) or np.any(np.isinf(raw_traj)):
                raise ValueError("NaN ë˜ëŠ” Inf ê°’ ë°œê²¬")
            
            # SE(2) â†’ SE(3) ë³€í™˜
            se3_matrices = []
            for i, pose in enumerate(raw_traj):
                x, y, yaw = pose
                se3_matrix = torch.eye(4, dtype=torch.float64)
                se3_matrix[0, 3] = x
                se3_matrix[1, 3] = y
                se3_matrix[0, 0] = torch.cos(torch.tensor(yaw, dtype=torch.float64))
                se3_matrix[0, 1] = -torch.sin(torch.tensor(yaw, dtype=torch.float64))
                se3_matrix[1, 0] = torch.sin(torch.tensor(yaw, dtype=torch.float64))
                se3_matrix[1, 1] = torch.cos(torch.tensor(yaw, dtype=torch.float64))
                se3_matrices.append(se3_matrix)
            
            se3_trajectory = torch.stack(se3_matrices)
            
            if self.verbose:
                print(f"      ğŸ”§ SE(3) ë³€í™˜ ì™„ë£Œ: {se3_trajectory.shape}")
            
            # SE(3) B-spline + SLERP ìŠ¤ë¬´ë”©
            smoothed_se3 = traj_smooth_se3_bspline_slerp(
                se3_trajectory,
                pos_method="bspline_scipy",
                degree=3,
                smooth=0.01
            )
            
            if self.verbose:
                print(f"      ğŸ”§ SE(3) ìŠ¤ë¬´ë”© ì™„ë£Œ: {smoothed_se3.shape}")
            
            # Arc-length ì¬ìƒ˜í”Œë§ (ì˜µì…˜) - ì¼ë‹¨ ë¹„í™œì„±í™”
            # if len(smoothed_se3) > 10:
            #     try:
            #         resampled_se3 = traj_resample_by_arclength(
            #             smoothed_se3, 
            #             num_samples=len(raw_traj)
            #         )
            #         smoothed_se3 = resampled_se3
            #     except Exception as e:
            #         if self.verbose:
            #             print(f"      âš ï¸ ì¬ìƒ˜í”Œë§ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            
                        # ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            smoothed_traj = self._convert_trajectory_format(smoothed_se3, self.output_format)
            
            if self.verbose:
                print(f"      ğŸ”§ {self.output_format} ë³€í™˜ ì™„ë£Œ: {smoothed_traj.shape}")
            
            # í†µê³„ ê³„ì‚°
            stats = {
                'method': 'SE3_bspline_slerp',
                'original_points': len(raw_traj),
                'smoothed_points': len(smoothed_traj),
                'success': True
            }
            
            return smoothed_traj, stats
            
        except Exception as e:
            error_msg = f"SE(3) ìŠ¤ë¬´ë”© ì‹¤íŒ¨: {e}"
            if self.verbose:
                print(f"      âŒ {error_msg}")
                import traceback
                traceback.print_exc()
            
            return None, {
                'method': 'SE3_bspline_slerp',
                'original_points': len(raw_traj) if raw_traj is not None else 0,
                'smoothed_points': 0,
                'success': False,
                'error': error_msg
            }
    
    def _process_single_environment(self, env_group_in: h5py.Group, f_out: h5py.File, env_name: str):
        """ë‹¨ì¼ í™˜ê²½ ì²˜ë¦¬"""
        self._monitor_memory(f"{env_name} ì‹œì‘ ì „")
        
        # ì¶œë ¥ í™˜ê²½ ê·¸ë£¹ ìƒì„±
        env_group_out = f_out.create_group(env_name)
        
        try:
            pair_ids = list(env_group_in.keys())
        except Exception as e:
            print(f"  âŒ {env_name}: í˜ì–´ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            return
        
        successful_pairs = 0
        failed_pairs = 0
        
        for pair_id in pair_ids:
            try:
                pair_group_in = env_group_in[pair_id]
            except Exception as e:
                print(f"  âŒ {env_name}/{pair_id}: í˜ì–´ ê·¸ë£¹ ì ‘ê·¼ ì‹¤íŒ¨ - {e}")
                failed_pairs += 1
                continue
            
            if 'raw_trajectory' not in pair_group_in:
                print(f"  âš ï¸ {env_name}/{pair_id}: raw_trajectory ì—†ìŒ")
                failed_pairs += 1
                continue
            
            try:
                # Raw trajectory ë¡œë“œ
                raw_trajectory = pair_group_in['raw_trajectory'][:]
                
                # ì¶œë ¥ í˜ì–´ ê·¸ë£¹ ìƒì„±
                pair_group_out = env_group_out.create_group(pair_id)
                
                # Raw trajectory ë³µì‚¬
                pair_group_out.create_dataset('raw_trajectory', data=raw_trajectory, compression='gzip')
                
                # ê¸°ì¡´ ì†ì„± ë³µì‚¬
                for key, value in pair_group_in.attrs.items():
                    pair_group_out.attrs[key] = value
                
                # SE(3) ìŠ¤ë¬´ë”© ìˆ˜í–‰
                smooth_trajectory, smooth_stats = self._se3_smooth_trajectory(raw_trajectory)
                
                if smooth_trajectory is not None:
                    # ìŠ¤ë¬´ë”©ëœ ê¶¤ì  ì €ì¥
                    pair_group_out.create_dataset('smooth_trajectory', data=smooth_trajectory, compression='gzip')
                    
                    # ìŠ¤ë¬´ë”© ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    pair_group_out.attrs['smooth_method'] = smooth_stats['method']
                    pair_group_out.attrs['smooth_success'] = smooth_stats['success']
                    pair_group_out.attrs['smooth_points'] = smooth_stats['smoothed_points']
                    
                    successful_pairs += 1
                    if self.verbose:
                        print(f"  âœ… {env_name}/{pair_id}: ìŠ¤ë¬´ë”© ì™„ë£Œ ({len(raw_trajectory)} â†’ {len(smooth_trajectory)} í¬ì¸íŠ¸)")
                else:
                    # ìŠ¤ë¬´ë”© ì‹¤íŒ¨ ì‹œì—ë„ ë©”íƒ€ë°ì´í„° ì €ì¥
                    pair_group_out.attrs['smooth_success'] = False
                    pair_group_out.attrs['smooth_error'] = smooth_stats.get('error', 'Unknown error')
                    failed_pairs += 1
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del raw_trajectory
                if smooth_trajectory is not None:
                    del smooth_trajectory
                
            except Exception as e:
                print(f"  âŒ {env_name}/{pair_id}: ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")
                failed_pairs += 1
        
        # í™˜ê²½ ë ˆë²¨ í†µê³„ ì—…ë°ì´íŠ¸
        self.stats['total_trajectories'] += (successful_pairs + failed_pairs)
        self.stats['successful_smoothing'] += successful_pairs
        self.stats['failed_smoothing'] += failed_pairs
        
        print(f"  ğŸ“Š {env_name}: {successful_pairs}/{successful_pairs + failed_pairs} ì„±ê³µ")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def process_file(self) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì¼ ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            with h5py.File(self.input_file, 'r') as f_in:
                with h5py.File(self.output_file, 'w') as f_out:
                    
                    # ë©”íƒ€ë°ì´í„° ë³µì‚¬
                    if 'metadata' in f_in:
                        f_in.copy('metadata', f_out)
                        print("âœ… ë©”íƒ€ë°ì´í„° ë³µì‚¬ ì™„ë£Œ")
                    
                    if 'global_stats' in f_in:
                        f_in.copy('global_stats', f_out)
                        print("âœ… ì „ì—­ í†µê³„ ë³µì‚¬ ì™„ë£Œ")
                    
                    # í™˜ê²½ ëª©ë¡ ë¡œë“œ
                    env_names = [name for name in f_in.keys() 
                                if name not in ['metadata', 'global_stats']]
                    self.stats['total_environments'] = len(env_names)
                    
                    print(f"\nğŸ¯ ì´ {len(env_names)}ê°œ í™˜ê²½ ì²˜ë¦¬ ì‹œì‘")
                    
                    # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                    for i in range(0, len(env_names), self.chunk_size):
                        env_chunk = env_names[i:i+self.chunk_size]
                        
                        print(f"\nğŸ“¦ ì²­í¬ {i//self.chunk_size + 1}/{(len(env_names)-1)//self.chunk_size + 1}: {len(env_chunk)}ê°œ í™˜ê²½")
                        
                        for env_name in env_chunk:
                            try:
                                env_group_in = f_in[env_name]
                                self._process_single_environment(env_group_in, f_out, env_name)
                                self.stats['processed_environments'] += 1
                            except Exception as e:
                                print(f"  âŒ {env_name}: í™˜ê²½ ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")
                        
                        # ì²­í¬ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
                        self._monitor_memory("ì²­í¬ ì™„ë£Œ í›„")
                        
                        # ì§„í–‰ë¥  ì¶œë ¥
                        progress = min(i + self.chunk_size, len(env_names))
                        print(f"ğŸ“Š ì§„í–‰ë¥ : {progress}/{len(env_names)} ({progress/len(env_names)*100:.1f}%)")
            
            # ì²˜ë¦¬ ì™„ë£Œ
            self.stats['processing_time'] = time.time() - start_time
            
            print(f"\nğŸ‰ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì…ë ¥ íŒŒì¼: {self.input_file}")
            print(f"   ì¶œë ¥ íŒŒì¼: {self.output_file}")
            print(f"   ì²˜ë¦¬ëœ í™˜ê²½: {self.stats['processed_environments']}/{self.stats['total_environments']}")
            print(f"   ì´ ê¶¤ì : {self.stats['total_trajectories']}")
            print(f"   ìŠ¤ë¬´ë”© ì„±ê³µ: {self.stats['successful_smoothing']}")
            print(f"   ìŠ¤ë¬´ë”© ì‹¤íŒ¨: {self.stats['failed_smoothing']}")
            
            if self.stats['total_trajectories'] > 0:
                success_rate = (self.stats['successful_smoothing'] / self.stats['total_trajectories']) * 100
                print(f"   ì„±ê³µë¥ : {success_rate:.1f}%")
            
            print(f"   ì²˜ë¦¬ ì‹œê°„: {self.stats['processing_time']:.2f}ì´ˆ")
            print(f"   ë©”ëª¨ë¦¬ ê²½ê³ : {self.stats['memory_warnings']}íšŒ")
            
            return self.stats
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {}


def main():
    parser = argparse.ArgumentParser(description='í†µí•© ê¶¤ì  ìŠ¤ë¬´ë”© ì‹œìŠ¤í…œ')
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument('--input', required=True, help='ì…ë ¥ HDF5 íŒŒì¼')
    parser.add_argument('--output', required=True, help='ì¶œë ¥ HDF5 íŒŒì¼')
    
    # ì˜µì…˜ ì¸ì
    parser.add_argument('--chunk-size', type=int, default=20, 
                       help='í™˜ê²½ ì²­í¬ í¬ê¸° (ê¸°ë³¸: 20)')
    parser.add_argument('--memory-threshold', type=float, default=75.0,
                       help='ë©”ëª¨ë¦¬ ê²½ê³  ì„ê³„ê°’ %% (ê¸°ë³¸: 75.0)')
    
    # ì¶œë ¥ í˜•ì‹
    parser.add_argument('--output-format', type=str, default='se3_6d',
                       choices=['se2', 'se3', 'se3_6d', 'quaternion_7d'],
                       help='ê¶¤ì  ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: se3_6d)')
    
    parser.add_argument('--verbose', action='store_true',
                       help='ìƒì„¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(args.input).exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.input}")
        return 1
    
    # ì¶œë ¥ íŒŒì¼ ë®ì–´ì“°ê¸° í™•ì¸
    if Path(args.output).exists():
        response = input(f"âš ï¸ ì¶œë ¥ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {args.output}\n   ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            print("ğŸš« ì‘ì—… ì·¨ì†Œë¨")
            return 1
    
    try:
            # ìŠ¤ë¬´ë” ìƒì„± ë° ì‹¤í–‰
    smoother = IntegratedTrajectorySmoother(
        input_file=args.input,
        output_file=args.output,
        chunk_size=args.chunk_size,
        memory_threshold=args.memory_threshold,
        verbose=args.verbose,
        output_format=args.output_format
    )
        
        stats = smoother.process_file()
        
        if not stats:
            print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
            return 1
        
        print("\nâœ… ìŠ¤ë¬´ë”© ì™„ë£Œ!")
        return 0
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)