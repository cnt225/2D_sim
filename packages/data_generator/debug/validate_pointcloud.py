#!/usr/bin/env python3
"""
Point Cloud Metadata Validator

í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„°ì˜ ì¼ê´€ì„±ì„ ê²€ì¦í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
- ë©”íƒ€ë°ì´í„°ì˜ num_pointsì™€ ì‹¤ì œ PLY íŒŒì¼ì˜ í¬ì¸íŠ¸ ê°œìˆ˜ ë¹„êµ
- ë¶ˆì¼ì¹˜í•˜ëŠ” ì¼€ì´ìŠ¤ë“¤ì˜ ì¸ë±ìŠ¤ì™€ ì°¨ì´ ë¶„ì„  
- ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì • ê¸°ëŠ¥ ì œê³µ

Author: GitHub Copilot & dhkang225
Date: 2025-08-11
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import argparse
import datetime


class PointCloudValidator:
    """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë©”íƒ€ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.validation_results: List[Dict] = []
        
    def read_ply_point_count(self, ply_path: Path) -> Optional[int]:
        """PLY íŒŒì¼ì—ì„œ ì‹¤ì œ í¬ì¸íŠ¸ ê°œìˆ˜ë¥¼ ì½ì–´ì˜´
        
        Args:
            ply_path: PLY íŒŒì¼ ê²½ë¡œ
            
        Returns:
            í¬ì¸íŠ¸ ê°œìˆ˜ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
        """
        try:
            with open(ply_path, 'r') as f:
                for line in f:
                    if line.startswith('element vertex'):
                        return int(line.split()[2])
            return None
        except Exception as e:
            print(f"Error reading PLY file {ply_path}: {e}")
            return None
    
    def read_metadata_point_count(self, meta_path: Path) -> Optional[int]:
        """ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ì—ì„œ num_pointsë¥¼ ì½ì–´ì˜´
        
        Args:
            meta_path: ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            í¬ì¸íŠ¸ ê°œìˆ˜ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
        """
        try:
            with open(meta_path, 'r') as f:
                metadata = json.load(f)
                return metadata.get('num_points')
        except Exception as e:
            print(f"Error reading metadata file {meta_path}: {e}")
            return None
    
    def validate_single_file(self, env_index: str) -> Dict:
        """ë‹¨ì¼ í™˜ê²½ íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ì™€ ì‹¤ì œ í¬ì¸íŠ¸ ìˆ˜ë¥¼ ê²€ì¦
        
        Args:
            env_index: í™˜ê²½ ì¸ë±ìŠ¤ (ì˜ˆ: "000571")
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        ply_path = self.data_dir / f"circle_env_{env_index}.ply"
        meta_path = self.data_dir / f"circle_env_{env_index}_meta.json"
        
        result = {
            'env_index': env_index,
            'ply_path': str(ply_path),
            'meta_path': str(meta_path),
            'ply_exists': ply_path.exists(),
            'meta_exists': meta_path.exists(),
            'actual_points': None,
            'metadata_points': None,
            'is_consistent': False,
            'difference': 0,
            'error': None
        }
        
        if not result['ply_exists']:
            result['error'] = "PLY file not found"
            return result
            
        if not result['meta_exists']:
            result['error'] = "Metadata file not found"
            return result
        
        # PLY íŒŒì¼ì—ì„œ ì‹¤ì œ í¬ì¸íŠ¸ ê°œìˆ˜ ì½ê¸°
        actual_points = self.read_ply_point_count(ply_path)
        if actual_points is None:
            result['error'] = "Could not read point count from PLY file"
            return result
            
        # ë©”íƒ€ë°ì´í„°ì—ì„œ í¬ì¸íŠ¸ ê°œìˆ˜ ì½ê¸°
        metadata_points = self.read_metadata_point_count(meta_path)
        if metadata_points is None:
            result['error'] = "Could not read num_points from metadata"
            return result
        
        result['actual_points'] = actual_points
        result['metadata_points'] = metadata_points
        result['difference'] = actual_points - metadata_points
        result['is_consistent'] = (actual_points == metadata_points)
        
        return result
    
    def validate_all_files(self, verbose: bool = True) -> List[Dict]:
        """ëª¨ë“  í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ë“¤ì„ ê²€ì¦
        
        Args:
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if verbose:
            print(f"ğŸ” Validating point cloud files in: {self.data_dir}")
        
        # ëª¨ë“  PLY íŒŒì¼ ì°¾ê¸°
        ply_files = list(self.data_dir.glob("circle_env_*.ply"))
        ply_files = [f for f in ply_files if not f.name.endswith('.backup')]  # ë°±ì—… íŒŒì¼ ì œì™¸
        
        env_indices = []
        for ply_file in ply_files:
            # íŒŒì¼ëª…ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ (ì˜ˆ: circle_env_000571.ply -> 000571)
            match = re.search(r'circle_env_(\d+)\.ply$', ply_file.name)
            if match:
                env_indices.append(match.group(1))
        
        env_indices.sort()
        if verbose:
            print(f"ğŸ“ Found {len(env_indices)} environment files to validate")
        
        results = []
        inconsistent_count = 0
        
        for i, env_index in enumerate(env_indices):
            if verbose and i % 100 == 0:
                print(f"âš™ï¸  Processing {i+1}/{len(env_indices)}: circle_env_{env_index}")
            
            result = self.validate_single_file(env_index)
            results.append(result)
            
            if not result['is_consistent'] and result['error'] is None:
                inconsistent_count += 1
        
        self.validation_results = results
        
        if verbose:
            print(f"\nâœ… Validation completed:")
            print(f"   â€¢ Total files: {len(results)}")
            print(f"   â€¢ Consistent: {len(results) - inconsistent_count}")
            print(f"   â€¢ Inconsistent: {inconsistent_count}")
        
        return results
    
    def analyze_inconsistencies(self, max_details: int = 20) -> None:
        """ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ê³  ì¶œë ¥
        
        Args:
            max_details: ìƒì„¸ ì¶œë ¥í•  ìµœëŒ€ íŒŒì¼ ìˆ˜
        """
        inconsistent = [r for r in self.validation_results if not r['is_consistent'] and r['error'] is None]
        
        if not inconsistent:
            print("âœ… No inconsistencies found!")
            return
        
        print(f"\nğŸš¨ INCONSISTENCY ANALYSIS")
        print(f"Found {len(inconsistent)} inconsistent files:")
        
        # ì°¨ì´ë³„ë¡œ ê·¸ë£¹í•‘
        diff_groups = {}
        for result in inconsistent:
            diff = result['difference']
            if diff not in diff_groups:
                diff_groups[diff] = []
            diff_groups[diff].append(result)
        
        print(f"\nğŸ“Š Difference statistics:")
        for diff, items in sorted(diff_groups.items())[:10]:  # ìƒìœ„ 10ê°œë§Œ
            print(f"   â€¢ Difference {diff:+d}: {len(items)} files")
        if len(diff_groups) > 10:
            print(f"   â€¢ ... and {len(diff_groups) - 10} more difference values")
        
        print(f"\nğŸ“ Detailed inconsistent files (top {max_details}):")
        for result in inconsistent[:max_details]:
            print(f"   â€¢ circle_env_{result['env_index']}: "
                  f"PLY={result['actual_points']}, "
                  f"Meta={result['metadata_points']}, "
                  f"Diff={result['difference']:+d}")
        
        if len(inconsistent) > max_details:
            print(f"   â€¢ ... and {len(inconsistent) - max_details} more")
    
    def save_validation_report(self, output_path: str) -> None:
        """ê²€ì¦ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        report = {
            'validation_timestamp': datetime.datetime.now().isoformat(),
            'data_directory': str(self.data_dir),
            'total_files': len(self.validation_results),
            'consistent_files': len([r for r in self.validation_results if r['is_consistent']]),
            'inconsistent_files': len([r for r in self.validation_results if not r['is_consistent'] and r['error'] is None]),
            'error_files': len([r for r in self.validation_results if r['error'] is not None]),
            'results': self.validation_results
        }
        
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
        print(f"ğŸ“„ Validation report saved to: {output_path}")
    
    def fix_metadata(self, dry_run: bool = True) -> None:
        """ë¶ˆì¼ì¹˜í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ìˆ˜ì •
        
        Args:
            dry_run: Trueë©´ ì‹¤ì œ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ
        """
        inconsistent = [r for r in self.validation_results if not r['is_consistent'] and r['error'] is None]
        
        if not inconsistent:
            print("âœ… No inconsistencies to fix!")
            return
        
        print(f"\nğŸ› ï¸  FIXING METADATA")
        if dry_run:
            print("ğŸ” DRY RUN MODE - No files will be modified")
        else:
            print("âš ï¸  FIXING MODE - Files will be modified")
            print("ğŸ’¾ Creating backups for all modified files...")
        
        fixed_count = 0
        for result in inconsistent:
            meta_path = Path(result['meta_path'])
            
            try:
                # ë©”íƒ€ë°ì´í„° ì½ê¸°
                with open(meta_path, 'r') as f:
                    metadata = json.load(f)
                
                # num_points ì—…ë°ì´íŠ¸
                old_value = metadata['num_points']
                new_value = result['actual_points']
                metadata['num_points'] = new_value
                
                print(f"   â€¢ circle_env_{result['env_index']}: {old_value} -> {new_value}")
                
                if not dry_run:
                    # ë°±ì—… ìƒì„±
                    backup_path = meta_path.with_suffix('.json.backup')
                    if not backup_path.exists():
                        with open(backup_path, 'w') as f:
                            json.dump(json.load(open(meta_path)), f, indent=2)
                    
                    # ìˆ˜ì •ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
                    with open(meta_path, 'w') as f:
                        json.dump(metadata, f, indent=2)
                
                fixed_count += 1
                
            except Exception as e:
                print(f"âŒ Error fixing {meta_path}: {e}")
        
        action = "would be fixed" if dry_run else "fixed"
        print(f"\nâœ… {fixed_count} files {action}")
        
        if not dry_run:
            print("ğŸ’¾ Backup files created with .json.backup extension")
            print("ğŸ”„ To restore from backup: find /path -name '*.json.backup' -exec sh -c 'mv \"$1\" \"${1%.backup}\"' _ {} \\;")


def main():
    parser = argparse.ArgumentParser(
        description='Point Cloud Metadata Validator - í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë©”íƒ€ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ê²€ì¦ (ê²°ê³¼ëŠ” result/default í´ë”ì— ì €ì¥)
  python validate_pointcloud.py --data-dir /path/to/data

  # íŠ¹ì • í”„ë¡œì íŠ¸ í´ë”ë¡œ ê²°ê³¼ ì €ì¥
  python validate_pointcloud.py --data-dir /path/to/data --folder v2

  # ê²€ì¦ í›„ ë³´ê³ ì„œ ì €ì¥ (custom í´ë”)
  python validate_pointcloud.py --data-dir /path/to/data --folder custom -o my_report.json

  # ìˆ˜ì • ë¯¸ë¦¬ë³´ê¸° (ì‹¤ì œ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
  python validate_pointcloud.py --data-dir /path/to/data --folder test --dry-run

  # ì‹¤ì œ ë©”íƒ€ë°ì´í„° ìˆ˜ì • (ë°±ì—… ìƒì„±ë¨)
  python validate_pointcloud.py --data-dir /path/to/data --folder v1 --fix

ìì„¸í•œ ì‚¬ìš©ë²•ì€ README.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
        ''')
    
    parser.add_argument('--data-dir', 
                       required=True,
                       help='í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--folder', 
                       default='default',
                       help='ê²°ê³¼ ì €ì¥ìš© í”„ë¡œì íŠ¸ í´ë”ëª… (ê¸°ë³¸ê°’: default)')
    parser.add_argument('--output', '-o', 
                       default='validation_report.json',
                       help='ê²€ì¦ ë³´ê³ ì„œ ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: validation_report.json)')
    parser.add_argument('--fix', action='store_true',
                       help='ë¶ˆì¼ì¹˜í•˜ëŠ” ë©”íƒ€ë°ì´í„° ìˆ˜ì • (ë°±ì—… íŒŒì¼ ìƒì„±)')
    parser.add_argument('--dry-run', action='store_true',
                       help='ìˆ˜ì • ë¯¸ë¦¬ë³´ê¸° (ì‹¤ì œë¡œ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ')
    parser.add_argument('--max-details', type=int, default=20,
                       help='ìƒì„¸ ì¶œë ¥í•  ìµœëŒ€ ë¶ˆì¼ì¹˜ íŒŒì¼ ìˆ˜ (ê¸°ë³¸ê°’: 20)')
    
    args = parser.parse_args()
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        print(f"âŒ Error: Data directory does not exist: {data_dir}")
        return 1
    
    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
    script_dir = Path(__file__).parent
    result_dir = script_dir / "result" / args.folder
    output_path = result_dir / args.output
    
    if not args.quiet:
        print("ğŸ” Point Cloud Metadata Validator")
        print("=" * 50)
        print(f"ğŸ“ Results will be saved to: {result_dir}")
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = PointCloudValidator(data_dir)
    
    # ê²€ì¦ ì‹¤í–‰
    results = validator.validate_all_files(verbose=not args.quiet)
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    validator.analyze_inconsistencies(max_details=args.max_details)
    
    # ë³´ê³ ì„œ ì €ì¥
    validator.save_validation_report(str(output_path))
    
    # ìˆ˜ì • ì˜µì…˜ ì²˜ë¦¬
    if args.fix or args.dry_run:
        validator.fix_metadata(dry_run=args.dry_run)
        
        # ìˆ˜ì • í›„ ë‹¤ì‹œ ê²€ì¦í•œ ê²°ê³¼ë„ ì €ì¥
        if not args.dry_run:
            final_output_path = result_dir / f"final_{args.output}"
            validator.validation_results = []  # ê²°ê³¼ ì´ˆê¸°í™”
            validator.validate_all_files(verbose=False)  # ë‹¤ì‹œ ê²€ì¦
            validator.save_validation_report(str(final_output_path))
    
    if not args.quiet:
        print("\n" + "=" * 50)
        print("ğŸ‰ Validation completed successfully!")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
